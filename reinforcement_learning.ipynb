{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 《Reinforcement Learning》\n",
    "\n",
    "![](https://img5.doubanio.com/lpic/s3252446.jpg)\n",
    "\n",
    "## 目录\n",
    "\n",
    "- [0.书本介绍](#0.书本介绍)\n",
    "- [1. Introduction](#1.-Introduction)\n",
    "\n",
    "## 0.书本介绍\n",
    "\n",
    "[Reinforcement Learning](https://book.douban.com/subject/2866455/)\n",
    "\n",
    "作者: Richard S. Sutton / Andrew G. Barto \n",
    "\n",
    "内容简介：\n",
    "\n",
    "```\n",
    "Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. \n",
    "\n",
    "In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. \n",
    "\n",
    "The only necessary mathematical background is familiarity with elementary concepts of probability.\n",
    "\n",
    "The book is divided into three parts. \n",
    "\n",
    "Part I defines the reinforcement learning problem in terms of Markov decision processes. \n",
    "\n",
    "Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. \n",
    "\n",
    "Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.\n",
    "```\n",
    "\n",
    "其他重要学习资料：\n",
    "\n",
    "- [WildML的博客](http://www.wildml.com/2016/10/learning-reinforcement-learning/)\n",
    "\n",
    "- [David Silver’s Reinforcement Learning Course](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "**Reinforcement Learning** is learning what to do -- how to map situations to actions -- so as to maximize a numerical rewward signal.\n",
    "\n",
    "**Exploit vs Explore**: the agent has to **exploit** what it already knows in order to obtain reward, but it also has to **explore** in order to make better action selections in the future.\n",
    "\n",
    "**Elements of Reinforcement Learning**:\n",
    "   + **policy**: defines the learning agent's way of behaving at a given time. A policy is a mapping from perceived states of the environment to actions to be taken when in those states.\n",
    "   + **reward function**: defines the goal in a reinforcement learning problem. It maps each perceived state(or state-action pair) of the environment to a single number, a reward, indicating the intrinsic desirability of the state. A reward function indicates what is good in an immediate sense.\n",
    "   + **value function**: specifies what is good in the long run. The value of a state is the total amount of reward an agent can expect to accumulate over the future, starting from the state. It is values with which we are most concerned when making and evaluating decisions.\n",
    "   + **modle (of the environment)**: model is something that mimics the behavior of the environment. Given a state and action, the model might predict the resultant next state and reward.\n",
    "   \n",
    "**RL vs Evolutionary Methods**: Reinforcement learning involves learning while interacting with the environment, which evolutionary methods do not do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Evaluative Feedback\n",
    "\n",
    "What differs RL from others? RL **evaluates** the actions taken rather than **instructs** by giving correct actions.\n",
    "\n",
    "Evaluative feedback indicates how good the action taken is, but not whether it is best or the worst action possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
