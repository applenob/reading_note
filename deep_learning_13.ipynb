{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目录\n",
    "\n",
    "- [0.书本介绍](https://applenob.github.io/deep_learning_1#0.书本介绍)\n",
    "- [1. Introduction](https://applenob.github.io/deep_learning_1#1.-Introduction)\n",
    "- [2. Linear Algebra](https://applenob.github.io/deep_learning_2)\n",
    "- [3. Probability and Information Theory](https://applenob.github.io/deep_learning_3)\n",
    "- [4. Numerical Computation](https://applenob.github.io/deep_learning_4)\n",
    "- [5. Machine Learning Basics](https://applenob.github.io/deep_learning_5)\n",
    "- [6. Deep Feedforward Networks](https://applenob.github.io/deep_learning_6)\n",
    "- [7. Regularization for Deep Learning](https://applenob.github.io/deep_learning_7)\n",
    "- [8. Optimization for Training Deep Models](https://applenob.github.io/deep_learning_8)\n",
    "- [9. Convolutional Networks](https://applenob.github.io/deep_learning_9)\n",
    "- [10. Sequence Modeling: Recurrent and Recursive Nets](https://applenob.github.io/deep_learning_10)\n",
    "- [11. Practical Methodology](https://applenob.github.io/deep_learning_11)\n",
    "- [12. Application](https://applenob.github.io/deep_learning_12)\n",
    "- [13. Linear Factor Models](https://applenob.github.io/deep_learning_13)\n",
    "- [14. Autoencoders](https://applenob.github.io/deep_learning_14)\n",
    "- [15. Representation Learning](https://applenob.github.io/deep_learning_15)\n",
    "- [16. Structured Probabilistic Models for Deep Learning](https://applenob.github.io/deep_learning_16)\n",
    "- [17. Monte Carlo Methods](https://applenob.github.io/deep_learning_17)\n",
    "- [18. Confronting the Partition Function](https://applenob.github.io/deep_learning_18)\n",
    "- [19. Approximate Inference](https://applenob.github.io/deep_learning_19)\n",
    "- [20. Deep Generative Models](https://applenob.github.io/deep_learning_20)\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## 13. Linear Factor Models\n",
    "\n",
    "**线性因子模型（Linear Factor Models）**：线性因子模型通过随机线性解码器函数来定义，该函数通过对h的线性变换以及添加噪声来生成x。通常包含如下步骤：1.首先，我们从一个分布中采样解释性因子h，$h\\sim p(h)$，其中p(h)是一个因子分布，满足$p(h)=\\prod_i p(h_i)$；2.然后，我们对实值的可观察变量进行采样$x=Wh+b+noise$。\n",
    "\n",
    "**概率PCA、因子分析和其他线性因子模型**仅在对观测到x之前的噪声分布和隐变量h先验的选择上有所不同。\n",
    "\n",
    "**因子分析（Factor Analysis）**：隐变量先验是一个方差为单位矩阵的高斯分布$h \\sim N(h;0,I)$，同时假定在给定h的条件下观察值$x_i$是条件独立的。假设噪声是从对角协方差矩阵的高斯分布中采样的的，协方差矩阵为$ψ=diag(σ^2)$，容易看出，x服从多维正态分布，并满$x\\sim N(x;b,WW^⊤+ψ)$。\n",
    "\n",
    "**概率PCA（Probabilistic PCA）和**：在因子分析的基础上，使条件方差$σ^2_i$等于同一个值。x的协方差简化为$WW^⊤+σ^2_I$，或者等价的$x=Wh+b+σz$，其中$z\\sim N(z;0,I)$\n",
    "\n",
    "**独立成分分析（Independent Component Analysis, ICA）**：主要想法是：通过选择一个独立的p(h)，尽可能地恢复接近独立的潜在因子。每个训练样本对应一个时刻，每个$x_i$是一个传感器对混合信号的观察值，并且每个$h_i$是单个原始信号的一个估计。ICA的所有变种均要求p(h)是非高斯的。 这是因为如果p(h)是具有高斯分量的独立先验，则W是不可识别的。\n",
    "\n",
    "**慢特征分析（Slow Feature Analysis）**：是使用来自时间信号的信息学习不变特征的线性因子模型。慢特征分析的想法源于所谓的慢性原则。 其基本思想是，与场景中起描述作用的单个量度相比，场景的重要特性通常变化得非常缓慢。为了引入慢性原则，我们可以向代价函数添加以下项:$λ\\sum _tL(f(x^{(t+1)}),f(x^{(t)}))$。深度SFA已经被用于学习用在对象识别和姿态估计的特征。但是到目前为止，慢性原则尚未成为任何最先进应用的基础。究竟是什么因素限制了其性能仍有待研究，或许是慢度先验太过强势。\n",
    "\n",
    "**稀疏编码（Sparse Coding）**：是一个线性因子模型，已作为一种无监督特征学习和特征提取机制得到了广泛研究。 严格来说，术语”稀疏编码”是指在该模型中推断h值的过程，而”稀疏建模”是指设计和学习模型的过程，但是通常这两个概念都可以用术语”稀疏编码”描述。 稀疏编码模型通常假设线性因子有一个各向同性精度为β的高斯噪声：$p(x∣h)=N(x;Wh+b,\\frac{1}{β}I)$。分布p(h)通常选取为一个峰值仅在0点很尖锐的分布：$p(h_i)=Laplace(h_i;0,\\frac{2}{λ})=\\frac{λ}{4}e^{−\\frac{1}{2}λ|h_i|}$。$h^*$的表达式里包含了$||h||_1$，这导致了$h^*$向量的稀疏性。\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
