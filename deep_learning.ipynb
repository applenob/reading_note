{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 《Deep Learning》\n",
    "\n",
    "![](https://img3.doubanio.com/lpic/s29133163.jpg)\n",
    "\n",
    "## 目录\n",
    "\n",
    "- [0.书本介绍](#0.书本介绍)\n",
    "- [1. Introduction](#1.-Introduction)\n",
    "- [2. Linear Algebra](#2.-Linear-Algebra)\n",
    "- [3. Probability and Information Theory](#3.-Probability-and-Information-Theory)\n",
    "- [4. Numerical Computation](#4.-Numerical-Computation)\n",
    "- [5. Machine Learning Basics](#5.-Machine-Learning-Basics)\n",
    "- [6. Deep Feedforward Networks](#6.-Deep-Feedforward-Networks)\n",
    "- [7. Regularization for Deep Learning](#7.-Regularization-for-Deep-Learning)\n",
    "- [8. Optimization for Training Deep Models](#8.-Optimization-for-Training-Deep-Models)\n",
    "- [9. Convolutional Networks](#9.-Convolutional-Networks)\n",
    "- [10. Sequence Modeling: Recurrent and Recursive Nets](#10.-Sequence-Modeling:-Recurrent-and-Recursive-Nets)\n",
    "- [11. Practical Methodology](#11.-Practical-Methodology)\n",
    "- [12. Application](#12.-Application)\n",
    "- [13. Linear Factor Models](#13.-Linear-Factor-Models)\n",
    "- [14. Autoencoders](#14.-Autoencoders)\n",
    "- [15. Representation Learning](#15.-Representation-Learning)\n",
    "- [16. Structured Probabilistic Models for Deep Learning](#16.-Structured-Probabilistic-Models-for-Deep-Learning)\n",
    "- [17. Monte Carlo Methods](#17.-Monte-Carlo-Methods)\n",
    "- [18. Confronting the Partition Function](#18.-Confronting-the-Partition-Function)\n",
    "- [19. Approximate Inference](#19.-Approximate-Inference)\n",
    "- [20. Deep Generative Models](#20.-Deep-Generative-Models)\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "## 0.书本介绍\n",
    "\n",
    "[Deep Learning](https://book.douban.com/subject/26883982/)\n",
    "\n",
    "[原版阅读网站](http://www.deeplearningbook.org/)\n",
    "\n",
    "作者:  Ian Goodfellow / Yoshua Bengio / Aaron Courville \n",
    "\n",
    "内容简介：\n",
    "\n",
    "```\n",
    "\"Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.\" -- Elon Musk, co-chair of OpenAI; co-founder and CEO of Tesla and SpaceX\n",
    "Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning.\n",
    "The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models.\n",
    "Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.\n",
    "```\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "什么是**machine learning**? \n",
    "\n",
    "在原始的AI系统中，定义不同的case使用不同的解决方法，这称为“hard code”。进一步的AI系统需要一种去获取知识的能力，也就是从原始数据中发现模式（“Pattern”），这种能力就是**machine learning**。\n",
    "\n",
    "但是，一般的machine learning算法严重依赖于数据的**表示(representation)**，表示中包含的每份信息又称为**feature**。\n",
    "\n",
    "这又引发了一个新的问题，对于很多task，我们不知道应该提取什么样的特征（只能经验主义）。\n",
    "\n",
    "于是又有了**representation learning**，即使用machine learning不光光是学习reprsentation到output的映射（mapping），还要学习data到representation的映射。\n",
    "\n",
    "典型的表示学习算法是**autoencoder**。encoder函数是将输入数据映射成表示;decoder函数将表示映射回原始数据的格式。\n",
    "\n",
    "representation learning的难点：表示是多种多样的，一种表示学习算法很难覆盖多种层次和不同类型的表示。\n",
    "\n",
    "**Deep Learning**：使用多层次的结构，用简单的表示来获取高层的表示。这样，解决了上面的问题（一种方法）。\n",
    "\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/dl.png)\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "## 2. Linear Algebra\n",
    "\n",
    "- Scalars: 一个数；\n",
    "\n",
    "- Vctors: 一列数；\n",
    "\n",
    "- Matrices: 二位数组的数，每个元素由两个下标确定；\n",
    "\n",
    "- Tensors: 多维数组的数。\n",
    "\n",
    "***\n",
    "\n",
    "**转置（transpose）**：$(A^T)_{i,j}=A_{j,i}$\n",
    "\n",
    "**矩阵乘法**: $C=AB$， $C_{i,j}=\\sum_kA_{i,k}B_{k,j}$\n",
    "\n",
    "**元素乘法(element product; Hardamard product)**：$A \\bigodot B$\n",
    "\n",
    "**点乘(dot product)**: 向量**x**，**y**的点乘：  $x^Ty$\n",
    "\n",
    "**单位矩阵(identic matrix)**: $I_n$， 斜对角的元素值是1,其他地方都是0\n",
    "\n",
    "**逆矩阵（inverse matrix）**:$A^{-1}$, $A^{-1}A=I_n$\n",
    "\n",
    "方程Ax=b，如果A可逆，则$x=A^{-1}b$\n",
    "\n",
    "**线性组合（linear combination）**：将矩阵A看作是不同的列向量的组合[d1,d2,...,dn]，每个列响亮代表一个方向，x可以代表在每个方向上移动的距离，那么Ax=b可以理解成原点如何在A指定的各个方向上移动，最后到达b点。Ax即为线性组合，组合的对象是各个列向量，方式是x的元素。\n",
    "\n",
    "**生成空间（span）**：对所有的x，生成的点Ax的集合，即为A的生成空间。\n",
    "\n",
    "**范数（Norm）**：用来衡量vector的尺寸。$L^p$ norm:\n",
    "$$||x||_p = \\left ( \\sum_i{|x_i|^p} \\right )^{\\frac{1}{p}}$$\n",
    "\n",
    "**Frobenius-norm**: 用来衡量matrix的尺寸。类似于$L_2$ norm\n",
    "$$||A||_F=\\sqrt{\\sum_{i,j}{A_{i,j}^2}}$$\n",
    "\n",
    "**对角阵（diagnal matrix）**：除了对角线上的元素不为0,其他元素都为0。可以表示为diag(v)。\n",
    "\n",
    "**对称阵（symmetric matrix）**：$A=A^T$\n",
    "\n",
    "**单位向量（unit vector）**：$||x||_2 = 1$\n",
    "\n",
    "**正交（orthogonal）**：如果$x^Ty=0$，则向量x和向量y彼此正交。\n",
    "\n",
    "**正交归一化矩阵（orthonormal matrix）**：每行都相互正交并且都是单位向量。$A^TA=AA^T=I$，有$A^{-1}=A^T$。\n",
    "\n",
    "**特征分解**：特征向量v和特征值λ，满足：$Av = λv$，方阵A可以这样分解：$A=Vdiag(λ)V^{-1}$，其中,$V=[v^{(1)},...,v^{(n)}]$,$λ=[λ_1, ..., λ_n]^T$。特别的，如果A是一个实对称阵，那么$A=Q∧Q^T$\n",
    "\n",
    "**正定（positive definite）**：一个矩阵的所有特征值都是正的，则称这个矩阵正定。\n",
    "\n",
    "**奇异值分解（singular value decomposition）**：$A = UDV^T$，其中A是m×n矩阵；U是m×m正交矩阵，U的列向量称为左奇异向量，是$AA^T$的特征向量；D是m×n对角矩阵，对角线上的元素称为奇异值；V是正交n×n矩阵，V的列向量称为右奇异向量，是$A^TA$的特征向量。\n",
    "\n",
    "**伪逆（Moore-Penrose Pseudoinverse）**：$A^+ = VD^+U^T$，其中，$D^+$是由D的每个对角线元素取倒数（reciprocal）获得。\n",
    "\n",
    "**迹（Trace）**：$Tr(A) = \\sum_i A_{i,i} $，即对角线元素之和。\n",
    "\n",
    "**行列式（Determinant）**：det(A)，是一个将一个matrix映射到一个实数的function。行列式的值等于矩阵的所有特征值的乘积。\n",
    "\n",
    "**奇异矩阵（singular matrix）**：前提是方阵，如果A(n×n)为奇异矩阵（singular matrix）<=> A的秩$Rank(A)<n$；如果A(n×n)为非奇异矩阵（nonsingular matrix）<=> A满秩，$Rank(A)=n$。\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Probability and Information Theory\n",
    "\n",
    "### 概率论部分\n",
    "\n",
    "**频率学派概率（frequentist probability）**：认为概率和事件发生的频率相关；**贝叶斯学派概率（Bayesian probability）**：认为概率是的对某件事发生的确定程度，可以理解成是确信的程度（degree of belief）。\n",
    "\n",
    "**随机变量（random variable）**：一个可能随机获取不同值的变量。\n",
    "\n",
    "**概率质量函数（probability mass function，PMF）**：用来描述离散随机变量的概率分布。表示为P(x)，是状态到概率的映射。\n",
    "\n",
    "**概率密度函数（probability density function，PDF）**：用来描述连续随机变量的概率分布，p(x)。\n",
    "\n",
    "**条件概率（conditional probability）**：$P(y=y|x=x) = \\frac{P(y=y, x=x)}{P(x=x)}$\n",
    "\n",
    "**条件概率的链式法则（chain rule of conditional probability）**：$P(x^{(1)}, ..., x^{(n)}) = P(x^{(1)})\\prod^n_{i=2}P(x^{(i)}|x^{(1)}, ..., x^{(i-1)})$\n",
    "\n",
    "**独立（independence）**：$\\forall x ∈ x, y ∈ y, p(x=x, y=y) = p(x=x)p(y=y)$\n",
    "\n",
    "**条件独立（conditional independence）**：$\\forall x ∈ x, y ∈ y, z ∈ z,p(x=x, y=y | z=z) = p(x=x | z=z)p(y=y | z=z)$\n",
    "\n",
    "**期望（expectation）**：期望针对某个函数f(x)，关于概率分布P(x)的平均值。对离散随机变量：$E_{x \\sim P}[f(x)] = \\sum_xP(x)f(x)$；对连续随机变量：$E_{x \\sim p}[f(x)] = \\int P(x)f(x)dx$。期望是线性的：$E_x[αf(x)+βg(x)] = αE_x[f(x)]+βE_x[f(x)]$\n",
    "\n",
    "**方差（variance）**：用来衡量从随机变量x的分布函数f(x)中采样出来的一系列值和期望的偏差。$Var(x) = E[(f(x)-E[f(x)])^2]$，方差开平方即为标准差（standard deviation）。\n",
    "\n",
    "**协方差（covariance）**：用于衡量两组值之间的线性相关程度。$Cov(f(x), g(y)) = E[(f(x)-E[f(x)])(g(y)-E[g(y)])]$。独立比协方差为0更强，因为独立还排除了非线性的相关。\n",
    "\n",
    "**贝努力分布（Bernoulli Distribution）**：随机变量只有两种可能的分布，只有一个参数：Φ，即x=1的概率。\n",
    "\n",
    "**多项式分布（Multinoulli Distribution）**随机变量有k种可能的分布，参数是一个长度为k-1的向量p。\n",
    "\n",
    "**高斯分布（Gaussian Distribution）**即正态分布（normal distribution），$\\textit{N}(x;μ,σ^2) = \\sqrt{\\frac{1}{2πσ^2}}exp(-\\frac{1}{2σ^2}(x-μ)^2)$。中心极限定理（central limit theorem）认为，大量的独立随机变量的和近似于一个高斯分布，这一点可以大量使用在应用中，我们可以认为噪声是属于正态分布的。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/gauss.PNG)\n",
    "\n",
    "**多元正态分布（multivariate normal distribution）**：给定协方差矩阵$\\mathbf{Σ}$（正定对称），$\\textit{N}(x;μ,Σ) = \\sqrt{\\frac{1}{(2π)^ndet(Σ)}}exp(-\\frac{1}{2}(x-μ)^TΣ^{-1}(x-μ))$\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/MultivariateNormal.png/450px-MultivariateNormal.png)\n",
    "\n",
    "**指数分布（exponential distribution）**：在深度学习的有研究中，经常会用到在x=0点获得最高的概率的分布，$p(x; λ) = λ\\mathbf{1}_{x≥0}exp(-λx)$，或者：$f(x) = \\left\\{\\begin{matrix}λexp(-λx) \\;\\;\\;\\; x≥0 \\\\0 \\;\\;\\;\\; else \\end{matrix}\\right.$，其中λ > 0是分布的一个参数，常被称为率参数（rate parameter）。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/exp_dis.png)\n",
    "\n",
    "**拉普拉斯（Laplace Distribution）**：另一个可以在一个点获得比较高的概率的分布。$Laplace(x ;μ,γ) = \\frac{1}{2γ}exp(-\\frac{|x-μ|}{γ})$\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/laplace.jpg)\n",
    "\n",
    "**迪拉克分布（Dirac Distribution）**：$p(x) = δ(x-μ)$，这是一个泛函数。迪拉克分布经常被用于组成经验分布（empirical distribution）：$p(x) = \\frac{1}{m}\\sum_{i=1}^m{δ(x-x^{(i)})}$\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/dirac.png)\n",
    "\n",
    "**逻辑斯蒂函数（logistic function）**：$σ(x) = \\frac{1}{1+exp(-x)}$，常用来生成贝努力分布的Φ参数。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/logistic.png)\n",
    "\n",
    "**softplus function**: $ζ(x) = log(1+exp(x))$，是“取正”函数的“soft”版：$x^+ = max(0, x)$\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/softplus.png)\n",
    "\n",
    "**贝叶斯公式（Bayes' Rule）**：$P(x|y) = \\frac{P(x)P(y|x)}{P(y)}$\n",
    "\n",
    "### 信息论部分\n",
    "\n",
    "**信息论背后的直觉： 学习一件不太可能的事件比学习一件比较可能的事件更有信息量。**\n",
    "\n",
    "**信息（information）需要满足的三个条件**：1.比较可能发生的事件的信息量要少；2.比较不可能发生的事件的信息量要大；3.独立发生的事件之间的信息量应该是可以叠加的。\n",
    "\n",
    "**自信息（self-information）：**对事件x=x，$I(x) = -logP(x)$，满足上面三个条件，单位是nats（底为e）\n",
    "\n",
    "**香农熵（Shannon entropy）**：自信息只包含一个事件的信息，对于整个概率分布p(x)，不确定性可以这样衡量：$E_{x\\sim P}[I(x)] = -E_{x\\sim P}[logP(x)]$，也可以表示成H(P)。\n",
    "\n",
    "**KL散度（Kullback-Leibler divergence）**：衡量两个分布P(x)和Q(x)之间的差距。$D_{KL}(P||Q)=E_{x\\sim P}[log \\frac{P(x)}{Q(x)}]=E_{x\\sim P}[logP(x)-logQ(x)]$，注意$D_{KL}(P||Q)≠D_{KL}(Q||P)$\n",
    "\n",
    "**交叉熵（cross entropy）**：$H(P,Q)=H(P)+D_{KL}(P||Q)=-E_{x\\sim P}[logQ(x)]$，假设P是真实分布，Q是模型分布，那么最小化交叉熵H(P,Q)可以让模型分布逼近真实分布。\n",
    "\n",
    "### 图模型（Structured Probabilistic Models）\n",
    "\n",
    "**有向图模型（Directed Model）**：$p(x) = \\prod_i p(x_i | Pa_g(x_i))$， 其中$Pa_g(x_i)$是$x_i$的父节点。举例：\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/dg.png)\n",
    "\n",
    "$P(a,b,c,d,e)=p(a)p(b|a)p(c|a,b)p(d|b)p(e|c)$\n",
    "\n",
    "**无向图模型（Undirected Model）**：所有节点都彼此联通的集合称作“团”（Clique）。$p(x)=\\frac{1}{Z}\\prod_i{Φ^{(i)}(C^{(i)})}$，其中，Φ称作facor，每个factor和一个团（clique）相对应。举例：\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/udg.png)\n",
    "\n",
    "$p(a,b,c,d,e) = \\frac{1}{Z}Φ^{(1)}(a,b,c)Φ^{(2)}(b,d)Φ^{(3)}(c,e)$\n",
    "\n",
    "****\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Numerical Computation\n",
    "\n",
    "**数值优化（Numerical Computation）**：通常指代那些在解决数学问题时，不使用从符号表达式中直接推导出解析解，而是使用迭代更新的方式获取答案的算法。\n",
    "\n",
    "**上溢和下溢（overflow/underflow）**：数据太小或者太大，在计算机内存中无法表示。\n",
    "\n",
    "**优化问题（optimization problem）**：优化目标：最小化函数：损失函数（loss function）/ 错误函数（error function）通常上标\\*表示最优解。$x^*=argmin f(x)$\n",
    "\n",
    "**临界点（critical point）**：$f'(x)=0$的点称为临界点，一般临界点取得极大值或者极小值，否则为鞍点（saddle point）。\n",
    "\n",
    "**梯度下降（gradient descent）**：$x' = x-ε\\triangledown _xf(x)$，其中，ε是学习率。\n",
    "\n",
    "**Jacobian 矩阵（Jacobian matrix）**：如果我们有一个函数f:$\\mathbb{R}^m \\rightarrow \\mathbb{R}^n$，那么Jacobian矩阵即为：$J_{i,j} = \\frac {\\partial}{\\partial x_j}f(x)_i$。\n",
    "\n",
    "**Hessian 矩阵（Hessian matrix）**：$H(f)(x)_{i,j} = \\frac {\\partial ^2}{\\partial x_i \\partial x_j}f(x)$。可以知道，Hessian矩阵是对称阵。\n",
    "\n",
    "**牛顿法（Newton's method）**：将函数用二阶的泰勒公式近似：$f(x)≈f(x^{(0)})+(x-x^{(0)})^T\\triangledown_xf(x^{(0)})+\\frac{1}{2}(x-x^{(0)})^TH(f)(x^{(0)})(x-x^{(0)})$，求解临界点$x^* = x^{(0)}-H(f)(x^{(0)})^{-1}\\triangledown_xf(x^{(0)})$。梯度下降称为“一阶优化算法”；牛顿法称为“二阶优化算法”。\n",
    "\n",
    "**KKT方法求解约束优化（constrained optimization）问题**：约束空间$\\mathbb{S}=\\{x|\\forall i, g^{(i)}(x)=0\\, and\\, \\forall j, h^{(j)}(x)\\leq 0\\}$，g称为等式约束，h称为不等式约束。引入变量$λ_i$和$α_j$，称为KKT乘子。拉格朗日函数（generalized Lagrangian）：$L(x,λ,α)=f(x)+\\sum _iλ_ig^{(i)}(x) + \\sum _jα_jh^{(j)}(x) $，则$\\underset{x}{min}\\underset{λ}{max}\\underset{α,α\\geq 0}{max}L(x,λ,α)$等价于$\\underset{x∈\\mathbb{S}}{min}f(x)$。KKT条件：1.拉格朗日函数对x,λ,α求偏导都为0；2.对于不等式约束，$α\\bigodot h(x)=\\mathbf{0}$。\n",
    "\n",
    "****\n",
    "\n",
    "****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning Basics\n",
    "\n",
    "**机器学习定义**：一个计算机程序，如果它能做到在任务T中的性能P随着经验E可以提高，那就可以称它是关于某类任务T和性能衡量P，从经验E中学习。\n",
    "\n",
    "**机器学习任务（T）类别**：分类（classification）/缺失输入数据的分类（classification with missing data）/回归（regression）/转录（transciption）/机器翻译（machine translation）/结构化输出（structured output）/异常检测（anomaly detection）/合成和采样（synthesis and smapling）/缺失值填补（imputation of missing data）/去噪（denoising）/密度估计（density estimation）\n",
    "\n",
    "**机器学习的性能（P）**：P因为T的不同而不同。对于像分类/缺失输入数据的分类/转录，使用准确率（accuracy）来衡量性能；而对于密度估计，通常输出模型在一些样本上概率对数的平均值。\n",
    "\n",
    "**机器学习的经验（E）**：根据经验的不同，分为监督学习和无监督学习。监督学习：学习p(x)；无监督学习：学习p(y|x)。通常来说，无监督学习通常指代从不需要人工标注数据中提取信息。\n",
    "\n",
    "**泛化（generalization）**：在先前未观测到的输入上表现良好的能力被称为泛化。\n",
    "\n",
    "**欠拟合（underfitting）和过拟合（overfitting）**：机器学习的性能取决于两点因素：1.使训练误差更小；2.使训练误差和测试误差的差距更小。分别对应欠拟合的改善和过拟合的改善。\n",
    "\n",
    "**模型的容量（capacity）**：模型的容量是指其拟合各种函数的能力。\n",
    "\n",
    "**VC维（Vapnik-Chervonenkis dimension）**：VC维用来度量二分类器的容量。假设存在m个不同的x点的训练集，分类器可以任意地标记该m个不同的x点，VC维即m的最大可能值。[详细解释](http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/)\n",
    "\n",
    "**奥卡姆剃刀（Occam's razor）**：在同样能够解释已知观测现象的假设中，我们应该挑选”最简单”的那一个。\n",
    "\n",
    "**没有免费的午餐定理（no free lunch theorem）**：所有分类算法在分类没有见过的点的时候，他们的错误率的期望是一样的。这个定理告诉我们，必须要针对特定的任务去设计机器学习算法。\n",
    "\n",
    "**正则化（Regularization）**：正则化是指我们针对减少泛化误差而不是训练误差，在一个机器学习算法上做的任何改动。\n",
    "\n",
    "**超参数（Hyperparameters）**：超参数的值不能通过学习算法本身学习出来。\n",
    "\n",
    "**验证集（Validation Sets）**：验证集用来调超参数。\n",
    "\n",
    "**最大似然估计（Maximum Likelihood Estimation, MLE）**：参数θ的最大似然估计：$θ_{ML} = \\underset{θ}{argmax}p_{model}(\\mathbb{X};θ) = \\underset{θ}{argmax}\\prod_{i=1}^mp_{model}(x^{(i)};θ)$。对数形式：$θ_{ML} = \\underset{θ}{argmax}\\sum_{i=1}^mlogp_{model}(x^{(i)};θ)$。是一种点估计方法。\n",
    "\n",
    "**贝叶斯统计（Bayesian Statistics）**：最大似然估计是频率学派的观点，认为参数θ是固定的，但是未知；贝叶斯统计观点认为，数据集是直接观察得到的，因此数据集不是随机的，但是参数θ是一个随机变量。$p(θ|x^{(1)},x^{(2)},...,x^{(m)}) = \\frac{p(x^{(1)},x^{(2)},...,x^{(m)}|θ)}p(θ){p(x^{(1)},x^{(2)},...,x^{(m)})}$\n",
    "\n",
    "**最大后验(Maximum A Posteriori, MAP)估计**：$θ_{MAP}=\\underset{θ}{argmax}p(θ∣x)=\\underset{θ}{argmax}logp(x∣θ)+logp(θ)$。是一种点估计方法。\n",
    "\n",
    "**机器学习算法的常见组成部分**：一个数据集（dataset）+一个损失函数（cost function）+一个优化过程（optimization procedure）+一个模型（model）\n",
    "\n",
    "**维数灾难（the Curse of Dimensionality）**：当数据的维数很高时，很多机器学习问题变得相当困难。 这种现象被称为维数灾难。\n",
    "\n",
    "**流形（manifold）学习**：流形指连接在一起的区域。 数学上，它是指一组点，且每个点都有其邻域。 给定一个任意的点，其流形局部看起来像是欧几里得空间。 日常生活中，我们将地球视为二维平面，但实际上它是三维空间中的球状流形。流形学习算法通过一个假设来克服这个障碍，该假设认为$R_n$中大部分区域都是无效的输入，有意义的输入只分布在包含少量数据点的子集构成的一组流形中，而学习函数的输出中，有意义的变化都沿着流形的方向或仅发生在我们切换到另一流形时。我们认为在人工智能的一些场景中，如涉及到处理图像、声音或者文本时，流形假设至少是近似对的。\n",
    "\n",
    "****\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deep Feedforward Networks\n",
    "\n",
    "**深度前馈网络（Deep Feedforward Networks）**：也被称为前馈神经网络（feedforward neural networks），或者多层感知机（multi-layer perceptrons， MLPs）是典型的深度学习模型。前馈网络的目标是去近似一个函数$f^*$。模型之所以称为前馈，是因为信息只向前流动，没有反馈的连接。\n",
    "\n",
    "**基于梯度的学习（Gradient Based Learning）**：神经网络模型和线性模型最大的区别在于神经网络的非线性使得损失函数不再是凸函数。这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值；而不是像用于训练线性回归模型的线性方程求解器，或者用于训练逻辑回归或~SVM~的凸优化算法那样保证全局收敛。 凸优化从任何一种初始参数出发都会收敛（理论上如此——在实践中也很鲁棒但可能会遇到数值问题）。 用于非凸损失函数的随机梯度下降没有这种收敛性保证，并且对参数的初始值很敏感。 对于前馈神经网络，将所有的权重值初始化为小随机数是很重要的。 偏置可以初始化为零或者小的正值。 \n",
    "\n",
    "**输出单元：**\n",
    "\n",
    "**1.用于高斯输出分布的线性单元（Linear Output Units）**：$\\hat y = W^Th+b$，通常用来预测条件高斯分布：$p(y|x)=N(y;\\hat y, I)$\n",
    "\n",
    "**2.用于Bernoulli输出分布的sigmoid单元（Sigmoid Output Units）**：二分类任务，可以通过这个输出单元解决。$\\hat y = σ(w^Th+b)$，其中，σ是sigmoid函数。\n",
    "\n",
    "**3.用于 Multinoulli输出分布的softmax单元（Softmax Output Units）**：$z=W^th+b$，而$softmax(z)_i=\\frac{exp(z_i)}{\\sum_jexp(z_j)}$，如果说argmax函数返回的是一个onehot的向量，那么softmax可以理解成soft版的argmax函数。\n",
    "\n",
    "**隐藏单元：**\n",
    "\n",
    "**1.修正线性单元（Rectified Linear Units，ReLU）**：使用激活函数$g(z)=max\\{0,z\\}$，有$h=g(W^Tx+b)$。通常b的初始值选一个小正值，如0.1。这样relu起初很可能是被激活的。relu的一个缺点是它不能在激活值是0的时候，进行基于梯度的学习。因此又产生了各种变体。\n",
    "\n",
    "**1.1.maxout单元：整流线性单元的一种扩展**：$g(z)_i=\\underset {j∈\\mathbb{G}(i)}{max}z_j$，其中，$\\mathbb{G}(i)$是第i组的输入索引集$\\{(i−1)k+1,…,ik\\}$。\n",
    "\n",
    "**2.logistic sigmoid与双曲正切函数（Hyperbolic Tangent）单元**：使用logistic sigmoid：$g(z)=σ(z)$；使用双曲正弦函数：$g(z)=tanh(z)$，其中, $tanh(z)=2σ(2z)-1$。 但是，在这两个函数的两端都很容易饱和，所以不鼓励用在隐藏单元中，一定要用可以优先选择双曲正弦函数。\n",
    "\n",
    "**通用近似性质（Universal Approximation Properties）**：一个前馈神经网络如果具有线性输出层和至少一层具有激活函数（例如logistic sigmoid激活函数）的隐藏层，只要给予网络足够数量的隐藏单元，它可以以任意的精度来近似任何从一个有限维空间到另一个有限维空间的Borel可测函数。 虽然具有单层的前馈网络足以表示任何函数，但是网络层可能大得不可实现，并且可能无法正确地学习和泛化。 在很多情况下，使用更深的模型能够减少表示期望函数所需的单元的数量，并且可以减少泛化误差。\n",
    "\n",
    "**MLP的深度（Depth）**：具有d个输入、深度为l、每个隐藏层具有n个单元的深度整流网络可以描述的线性区域的数量是$O(\\begin{pmatrix}\n",
    "n\\\\\n",
    "d\n",
    "\\end{pmatrix}^{d(l−1)}n^d)$,意味着，这是深度l的指数级。\n",
    "\n",
    "**后向传播算法（Back-Propagation）**：后向传播算法将偏差（cost）在网络中从后往前传播，用来计算关于cost的梯度。后向传播算法本身不是学习算法，而是学习算法，像SGD，使用后向传播算法来计算梯度。对于bp的生动理解，可以参考[知乎的这个回答](https://zhihu.com/question/27239198/answer/89853077)，“同样是利用链式法则，BP算法则机智地避开了这种冗余，它对于每一个路径只访问一次就能求顶点对所有下层节点的偏导值”；“BP算法就是主动还款。e把所欠之钱还给c，d。c，d收到钱，乐呵地把钱转发给了a，b，皆大欢喜”。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/fp.png)\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/bp.png)\n",
    "\n",
    "**计算图（Computational Graphs）**：节点代表变量（variable）；引入操作（operation）的概念，操作是一个或者多个变量的函数，如果一个变量y是由一个对于变量x的操作得来的，那么就可以画一条有向边，从x指向y；\n",
    "\n",
    "**微积分中的链式法则（Chain Rule）**：假设y=g(x)，z=f(g(x))=f(y)，那么有$\\frac{dz}{dx}=\\frac{dz}{dy}\\frac{dy}{dx}$；进一步，如果$x∈R^m，y∈R^n，g：R^m \\rightarrow R^n，f：R^n \\rightarrow R$，有$\\frac{\\partial z}{\\partial x_i}=\\sum_j \\frac{\\partial z}{\\partial y_j}\\frac{\\partial y_j}{\\partial x_i}$，可以写成向量形式：$\\triangledown _xz(\\frac{\\partial y}{\\partial x})^T\\triangledown _yz$，其中，$\\frac{\\partial y}{\\partial x}$是n×m的g的Jacobian矩阵。\n",
    "\n",
    "**不同框架的bp实现**：1.\"symbol-to-number\"：以计算图和数值作为图的输入，返回一系列数值，作为输入的梯度。**Torch**，**Caffe**。2.\"symbol-to-symbol\"：以计算图作为输入，开辟额外的图，来保存需要的微分的符号表示。这种方法可以在学习算法中多次使用，并且可以用来计算更高阶的微分。\n",
    "\n",
    "****\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Regularization for Deep Learning\n",
    "\n",
    "**正则化（Regularization）**：对学习算法的修改——旨在减少泛化误差而不是训练误差。\n",
    "\n",
    "**参数范数惩罚（Parameter Norm Penalties）**：通过对目标函数J添加一个**参数范数惩罚Ω(θ)**，来限制模型的学习能力。 我们将正则化后的目标函数记为$\\tilde{J}$：$\\tilde{J}(θ;X,y)=J(θ;X,y)+αΩ(θ)$，其中α∈[0,∞)是权衡范数惩罚项Ω和标准目标函数 J(X;θ)相对贡献的超参数。说明，在神经网络中我们通常只对每一层仿射变换的**权重w**做惩罚而不对偏置做正则惩罚。典型的参数范数惩罚有$L^2$参数正则和$L^1$参数正则。\n",
    "\n",
    "**$L^2$参数正则（$L^2$ Parameter Regularization）**：也就是**权重衰减（weight decay）**，罚项为$Ω(θ)=\\frac{1}{2}||w||_2^2$，也称为岭回归（ridge regression）或Tikhonov正则。 在训练过程中，只有在显著减小目标函数方向上的参数会保留得相对完好；在无助于目标函数减小的方向（对应~Hessian~矩阵较小的特征值）上改变参数不会显著增加梯度。 这种不重要方向对应的分量会在训练过程中因正则化而衰减掉。\n",
    "\n",
    "**$L^1$参数正则（$L^1$ Parameter Regularization）**：罚项为$Ω(θ)=||w||_1=\\sum_i|w_i|$，相比于$L^2$正则，$L^1$正则产生更多的稀疏性结果，此处稀疏性指的是最优值中的一些参数为0。这一性质也使得$L^1$正则在**特征选择**机制中被广泛使用。\n",
    "\n",
    "**作为约束的范数惩罚**：我们可以把参数范数惩罚看作对权重强加的约束。 如果Ω是$L^2$范数，那么权重就是被约束在一个$L^2$球中。 如果Ω是$L^1$范数，那么权重就是被约束在一个$L^1$范数限制的区域中。 \n",
    "\n",
    "**数据集增强（Dataset Augmentation）**：实际上，让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练。 但在实践中，我们拥有的数据量是很有限的。 解决这个问题的一种方法是创建假数据并添加到训练集中。这种方法用在分类任务来说是很简单的； 但这种方法对于其他许多任务来说并不那么容易，比如密度估计问题。 数据集增强在目标识别（objective recognition）和语音识别（speech recognition）上被证实比较有效。通常情况下，人工设计的数据集增强方案可以大大减少机器学习技术的泛化误差。\n",
    "\n",
    "**噪声鲁棒性（Noise Robustness）**：噪声可以直接注入到输入数据，作为数据集增强，向输入添加方差极小的噪声等价于对权重施加范数惩罚；也可以向隐藏单元添加噪声，这种罚项更加强大；可以直接向权重w注入噪声，经常用于rnn，它推动模型进入对权重小的变化相对不敏感的区域，找到的点不只是极小点，还是由平坦区域所包围的最小点；还可以向输出目标注入噪声，比如label smoothing。\n",
    "\n",
    "**半监督学习（Semi-Supervised Learning）**：在深度学习的背景下，半监督学习通常指的是学习一个表示：h=f(x)。 学习表示的目的是使相同类中的样本有类似的表示。\n",
    "\n",
    "**多任务学习（Multi-Task Learning）**：通过合并几个任务中的样例（可以视为对参数施加的软约束）来提高泛化的一种方式。 当模型的一部分在任务之间共享时，模型的这一部分更多地被约束为良好的值（假设共享是合理的），往往能更好地泛化。从深度学习的观点看，底层的先验知识如下：能解释数据变化的因素中，某些因素是跨两个或更多任务共享的。\n",
    "![]()\n",
    "\n",
    "**提前停止（Early Stopping）**：我们经常观察到，训练误差会随着时间的推移逐渐降低，但验证集的误差会再次上升。这意味着，如果在验证集误差开始上升的时候提前停止训练，这就是“提前终止”策略。可以获得更好的模型 可能是深度学习中最常用的正则化形式。 它的流行主要是因为有效性和简单性，还可以减少训练过程的计算成本。\n",
    "\n",
    "**参数绑定（Parameter Tying）**：A模型和已经有参数的模型B任务相似，可以让A尽可能接近B，设置罚项：$Ω(w^{(A)},w^{(B)})=‖w^{(A)}−w^{(B)}‖^2_2 $\n",
    "\n",
    "**参数共享（Parameter Sharing）**：直接让A模型的参数等于B模型的参数，典型的应用是CNN。\n",
    "\n",
    "**稀疏表示（Sparse Representation）**：惩罚神经网络中的激活单元，稀疏化激活单元，惩罚项：Ω(h)。稀疏表示和$L^1$正则带来的稀疏参数容易混淆，区别：![]()\n",
    "![]()\n",
    "\n",
    "**Bagging（Bootstrap Aggregating）**：通过结合多个模型来降低泛化误差。这种方法通常又被称为“集成方法”（Ensemble Method）。具体来说，Bagging涉及构造k个不同的数据集，再训练k个模型，集合所有模型的预测结果投票得出最后结果。模型平均是一个减少泛化误差的非常强大可靠的方法。 但在作为科学论文算法的基准时，它通常是不鼓励使用的，因为任何机器学习算法都可以从模型平均中大幅获益\n",
    "\n",
    "**Dropout**：Dropout可以被认为是集成大量深层神经网络的实用Bagging方法。 但是Dropout训练与Bagging训练不太一样。 在Bagging的情况下，所有模型都是独立的。 在Dropout的情况下，所有模型共享参数。 Dropout不仅仅是训练一个Bagging的集成模型， 并且是共享隐藏单元的集成模型。 这意味着无论其他隐藏单元是否在模型中，每个隐藏单元必须都能够表现良好。 隐藏单元必须准备好进行模型之间的交换和互换。 因此Dropout正则化每个隐藏单元不仅是一个很好的特征，更要在许多情况下是良好的特征。 除此之外，计算方便是Dropout的一个优点，Dropout的另一个显著优点是不怎么限制适用的模型或训练过程。 然而，当只有极少的训练样本可用时，Dropout不会很有效。\n",
    "\n",
    "**对抗训练（Adversarial Training）**： 对抗训练通过鼓励网络在训练数据附近的局部区域恒定来限制这一高度敏感的局部线性行为。 这可以被看作是一种明确地向监督神经网络引入局部恒定先验的方法。\n",
    "\n",
    "****\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optimization for Training Deep Models\n",
    "\n",
    "**机器学习和纯优化问题的区别**：机器学习关注某些性能度量P，定义于测试集上并且可能是不可解的，只能间接地优化P。因此通过降低代价函数J(θ)来提高P。 这一点与纯优化不同，纯优化最小化目标J本身。\n",
    "\n",
    "**批量（batch）梯度算法**：使用整个训练集的优化算法被称为批量（batch）或确定性（deterministic）梯度算法。\n",
    "\n",
    "**在线（online）算法**：每次只使用单个样本的优化算法有时被称为随机（stochastic）或者在线（online）算法。\n",
    "\n",
    "**mini batch**：介于以上两者之间，使用一个以上，而又不是全部的训练样本。影响mini batch size的因素：1.更大的批量会计算更精确的梯度估计，但是回报却是小于线性的。2.极小批量通常难以充分利用多核架构。 这促使我们使用一些绝对最小批量，低于这个值的小批量处理不会减少计算时间。3.在某些硬件上使用特定大小的数组时，运行时间会更少。 尤其是在使用GPU时，通常使用2的幂数作为批量大小可以获得更少的运行时间。\n",
    "\n",
    "**局部极小值（local minima）的问题**：如果一个足够大的训练集可以唯一确定一组模型参数，那么该模型被称为可辨认的（identifiable）；而神经网络模型是不可辨认的（最直观的原因就是权重空间对称性，weight space symmetry），这意味着神经网络代价函数具有非常多的局部极小值。 对于足够大的神经网络而言， 大部分局部极小值都具有很小的代价函数，我们能不能找到真正的全局最小点并不重要，而是需要在参数空间中找到一个代价很小（但不是最小）的点。\n",
    "\n",
    "**鞍点（Saddle）的问题**：对于很多高维非凸函数而言，局部极小值事实上远少于另一类梯度为零的点：鞍点。在鞍点处，Hessian矩阵同时具有正负特征值。鞍点激增对训练算法的影响：对于只使用梯度信息的一阶优化算法而言，目前情况还不清楚。 鞍点附近的梯度通常会非常小。 另一方面，实验中梯度下降似乎可以在许多情况下逃离鞍点。对于牛顿法而言，鞍点显然是一个问题。 梯度下降旨在朝”下坡”移动，而非明确寻求临界点。 而牛顿法的目标是寻求梯度为零的点。 高维空间中鞍点的激增或许解释了在神经网络训练中为什么二阶方法无法成功取代梯度下降。 \n",
    "\n",
    "**悬崖（cliffs）和梯度爆炸（exploding gradients）**：多层神经网络通常存在像悬崖一样的斜率较大区域，这是由于几个较大的权重相乘导致的，在RNN中比较常见。 遇到斜率极大的悬崖结构时，梯度更新会很大程度地改变参数值，通常会完全跳过这类悬崖结构。 启发式梯度截断会干涉来减小步长，从而使其不太可能走出梯度近似为最陡下降方向的悬崖区域。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/cliff.png)\n",
    "\n",
    "**各种优化算法**：\n",
    "\n",
    "**随机梯度下降（Stochastic Gradient Descent）算法**：计算mini-batch中m个样本对应的梯度，取其平均值来更新参数。关键的超参是学习率ϵ。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/8-1.png)\n",
    "\n",
    "**动量（Momentum）算法**：动量方法旨在加速学习，特别是处理高曲率、小但一致的梯度，或是带噪声的梯度。 动量算法使用变量v（velocity，速度）**积累之前梯度指数级衰减的移动平均**，并且继续沿该方向移动。动量=mv，当m=1时动量即v。如果动量算法总是观测到梯度g，那么它会在方向−g上不停加速，直到达到最终速度，其中步长大小为$\\frac{ϵ‖g‖}{1−α}$。因此将动量的超参数视为$\\frac{1}{1−α}$有助于理解。 例如，α=0.9对应着最大速度10倍于梯度下降算法。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/8-2.png)\n",
    "\n",
    "**Nesterov 动量算法**：Nesterov 动量算法和普通的动量算法的区别在于梯度计算的位置。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/8-3.png)\n",
    "\n",
    "**参数初始化策略**：现代的初始化策略是简单的、启发式的。也许完全确知的唯一特性是初始参数需要在不同单元间”破坏对称性”。更大的初始权重具有更强的破坏对称性的作用，有助于避免冗余的单元。有些启发式方法可用于选择权重的初始大小。 一种初始化m个输入和n输出的全连接层的权重的启发式方法是从分布$U(−\\frac{1}{\\sqrt{m}},\\frac{1}{\\sqrt{m}})$中采样权重，另一种使用标准初始化,$?W_{i,j}\\sim U(−\\frac{6}{\\sqrt{m+n}},\\frac{6}{\\sqrt{m+n}})$\n",
    "\n",
    "**自适应学习率的优化算法**：\n",
    "\n",
    "**AdaGrad**：反比于其所有梯度历史平方值总和的平方根来缩放每个参数。 累积参数梯度越大学习率下降越快。AdaGrad在某些深度学习模型上效果不错，但不是全部。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/8-4.png)\n",
    "\n",
    "**RMSProp**：修改AdaGrad以在非凸设定下效果更好，改变梯度积累为指数加权的移动平均。RMSProp使用指数衰减平均以丢弃遥远过去的历史，使其能够在找到凸碗状结构后快速收敛， 它就像一个初始化于该碗状结构的AdaGrad算法实例。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/8-5.png)\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/8-6.png)\n",
    "\n",
    "**Adam**：“Adam”这个名字派生自”adaptive moments”。它结合了RMSProp和动量算法。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/8-7.png)\n",
    "\n",
    "**二阶近似方法**：\n",
    "\n",
    "**牛顿法（Newton's Method）**：牛顿法的主要制约在于计算量巨大，每一次更新参数的迭代都需要计算$H^{-1}$，假如有k个参数，那么复杂度就是$O(k^3)$。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/8-8.png)\n",
    "\n",
    "**共轭法（Conjugate Gradients）**：共轭梯度是一种通过迭代下降的共轭方向以有效避免Hessian矩阵求逆计算的方法。在共轭梯度法中，我们寻求一个和先前线性搜索方向共轭的搜索方向。 在训练迭代t时，下一步的搜索方向$d_t$的形式如下：$d_t=∇_θJ(θ)+β_td_{t−1}$，其中，系数$βt$的大小控制我们应沿方向$d_{t−1}$加回多少到当前搜索方向上。所谓共轭，即两个方向$dt$和$d_{t−1}$，满足二次方程$d^⊤_tHd_{t−1}=0$。 对于二次曲面而言，共轭方向确保梯度沿着前一方向大小不变。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/8-9.png)\n",
    "\n",
    "**BFGS（Broyden-Fletcher-Goldfarb-Shanno）算法**：BFGS等拟牛顿法所采用的方法是使用矩阵$M_t$近似逆，迭代地低秩更新精度以更好地近似$H^{−1}$。$ρ_t=M_tg_t$，更新步骤：$θ_{t+1}=θ_t+ϵ^*ρ_t$。\n",
    "\n",
    "**批标准化（Batch Normalization）**：它并不是一个优化算法，而是一个自适应的重参数化的方法，试图解决训练非常深的模型的困难。批标准化提出了一种几乎可以重参数化所有深度网络的优雅方法。 重参数化显著减少了多层之间协调更新的问题。 批标准化可应用于网络的任何输入层或隐藏层。$H'=\\frac{H−μ}{σ}$，其中，$μ=\\frac{1}{m}∑_iH_{i,:}$，$σ=\\sqrt{δ+\\frac{1}{m}∑_i(H−μ)^2_i}$\n",
    "\n",
    "\n",
    "**坐标下降（Coordinate Descent）**：如果我们相对于某个单一变量$x_i$最小化f(x)，然后相对于另一个变量$x_j$等等，反复循环所有的变量，我们会保证到达（局部）极小值。 这种做法被称为坐标下降，因为我们一次优化一个坐标。 当一个变量的值很大程度地影响另一个变量的最优值时，坐标下降不是一个很好的方法。\n",
    "\n",
    "**Polyak平均**：Polyak平均会平均优化算法在参数空间访问轨迹中的几个点。当应用Polyak平均于非凸问题时，通常会使用指数衰减计算平均值：\n",
    "$θ^{(t)}=αθ^{(t−1)}+(1−α)θ^{(t)}$\n",
    "\n",
    "**监督预训练（Supervised Pretraning）**：有时，如果模型太复杂难以优化，或是如果任务非常困难，直接训练模型来解决特定任务的挑战可能太大。 因此可以训练一个较简单的模型来求解问题，然后使模型更复杂会更有效。 训练模型来求解一个简化的问题，然后转移到最后的问题，有时也会更有效些。 这些在直接训练目标模型求解目标问题之前，训练简单模型求解简化问题的方法统称为预训练。\n",
    "\n",
    "**设计有助于优化的模型**：改进优化的最好方法并不总是改进优化算法。 相反，深度模型中优化的许多改进来自于设计易于优化的模型。\n",
    "\n",
    "****\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Convolutional Networks\n",
    "\n",
    "**卷积网络（Convolutional Networks）**：卷积网络是指那些至少在网络的一层中使用卷积运算来替代一般的矩阵乘法运算的神经网络。\n",
    "\n",
    "**卷积（Convolution）操作**：卷积是一种特殊的线性运算。 假设我们正在用激光传感器追踪一艘宇宙飞船的位置，x(t)表示宇宙飞船在时刻t的位置，x和t都是实值。 假设我们的传感器受到一定程度的噪声干扰。 为了得到飞船位置的低噪声估计，我们对得到的测量结果进行平均。 显然，时间上越近的测量结果越相关，所以我们采用一种加权平均的方法，对于最近的测量结果赋予更高的权重。 采用一个加权函数w(a)来实现，其中a表示某个测量的测量时刻：$s(t)=∫x(a)w(t−a)da$，或者用离散的表达式：$s(t)=(x∗w)(t)=∑_{a=−∞}^∞x(a)w(t−a)$。这就是卷积操作，可以用星号表示：$s(t)=(x∗w)(t)$。 x是输入（input）；w是核（kernel）；输出的s是特征映射（feature map）。\n",
    "\n",
    "**互相关函数（cross-correlation）**：卷积操作在kernel中的变量是t-a，这保证了卷积操作是可交换的（commutative）。 许多神经网络库会实现一个相关的函数，称为互相关函数，和卷积运算几乎一样但是并没有对核进行翻转：$s(t)=∫x(a)w(a)da$。\n",
    "![]()\n",
    "\n",
    "**卷积运算改进机器学习系统的动机**：\n",
    "\n",
    "**1.稀疏交互（Sparse Interaction）**：传统的神经网络使用矩阵乘法来建立输入与输出的连接关系，每一个输出单元与每一个输入单元都产生交互；卷积网络具有稀疏交互（也叫做稀疏连接或者稀疏权重）的特征，这是使核的大小远小于输入的大小来达到的。 如果有m个输入和n个输出，那么矩阵乘法需要m×n个参数并且相应算法的时间复杂度为O(m×n)；如果我们限制每一个输出拥有的连接数为k，那么稀疏的连接方法只需要k×n个参数以及O(k×n)的运行时间。 在很多实际应用中，只需保持k比mm小几个数量级，就能在机器学习的任务中取得好的表现。\n",
    "![]()\n",
    "\n",
    "**2.参数共享（Parameter Sharing）**：参数共享是指在一个模型的多个函数中使用相同的参数。 在卷积神经网络中，核的每一个元素都作用在输入的每一位置上。 卷积在存储需求和统计效率方面极大地优于稠密矩阵的乘法运算。\n",
    "\n",
    "**3.等变表示（Equivariant Representation）**：参数共享的特殊形式使得神经网络层具有对平移等变的性质。 函数f(x)与g(x)满足f(g(x))=g(f(x))，就说f(x)对于变换g具有等变性(equivariant)。 \n",
    "\n",
    "**池化（pooling）**：池化函数使用某一位置的相邻输出的总体统计特征来代替网络在该位置的输出。 例如，最大池化函数（max pooling）给出相邻矩形区域内的最大值。 其他常用的池化函数包括相邻矩形区域内的平均值、L2范数以及基于据中心像素距离的加权平均函数。 不管采用什么样的池化函数，当输入作出少量平移时，池化能够帮助输入的表示近似不变。 对于平移的不变性是指当我们对输入进行少量平移时，经过池化函数后的大多数输出并不会发生改变。 **局部平移不变性**是一个很有用的性质，**尤其是当我们关心某个特征_是否出现_而不关心它出现的具体位置时**。\n",
    "\n",
    "**卷积与池化作为一种无限强的先验**：先验的强或者弱取决于先验中概率密度的集中程度：弱先验具有较高的熵值，例如方差很大的高斯分，这样的先验允许数据对于参数的改变具有或多或少的自由性； 强先验具有较低的熵值，例如方差很小的高斯分布，这样的先验在决定参数最终取值时起着更加积极的作用。 一个无限强的先验需要对一些参数的概率置零并且完全禁止对这些参数赋值，无论数据对于这些参数的值给出了多大的支持。 因此，我们可以把卷积的使用当作是对网络中一层的参数引入了一个无限强的先验概率分布。 这样做带来的一个关键的洞察是卷积和池化可能导致**欠拟合**；另一个关键洞察是当我们比较卷积模型的统计学习表现时，只能与其他卷积模型做比较。\n",
    "\n",
    "**深度学习框架下的卷积**：1.通常指由多个并行卷积组成的运算，可以在多个位置提取多种类型的特征。 2.输入通常也不仅仅是实值的网格，而是由一系列向量的网格，$Z_{i,j,k}=∑_{l,m,n}V_{l,j+m−1,k+n−1}K_{i,l,m,n}$。 3.使用stride，跳过核中的一些位置来降低计算的开销，$Z_{i,j,k}=∑_{l,m,n}[V_{l,(j-1)×s+m,(k-1)×s+n}K_{i,l,m,n}]$。 4.对输入用零进行填充（zero-padding）使得它加宽。 其中，valid convolution代表不使用padding，输入尺寸是m，输出为m-k+1；same convolution代表增加padding使得输出尺寸和输入相同都为m；full convolution代表增加padding，使得输出尺寸为m+k-1。 \n",
    "\n",
    "**其他卷积函数变体**：\n",
    "![]()\n",
    "**局部连接网络层（locally connected layers）**：$Z_{i,j,k}=∑_{l,m,n}[V_{l,j+m−1,k+n−1}w_{i,j,k,l,m,n}]$。**平铺卷积（tiled convolution）**：平铺卷积对卷积层和局部连接层进行了折衷。$Z_{i,j,k}=∑_{l,m,n}V_{l,j+m−1,k+n−1}K_{i,l,m,n,j\\%  t+1,k\\%t+1}$\n",
    "\n",
    "**卷积网络的训练**：假设我们想要训练这样一个卷积网络：它包含步幅为s的步幅卷积，该卷积的核为K，作用于多通道的图像V，定义为$c(K,V,s)$。 假设我们想要最小化某个损失函数$J(V,K)$。 在前向传播过程中，我们需要用c本身来输出Z，然后Z传递到网络的其余部分并且被用来计算损失函数J。 在反向传播过程中，我们会得到一个张量G满足：$G_{i,j,k}=\\frac{∂}{∂Z_{i,j,k}}J(V,K)$。 核参数的更新规则：$\\frac{∂}{∂K_{i, j, k, l}} J(V, K) = \\sum_{m, n} G_{i, m, n} V_{j, (m-1)× s+k, (n-1)× s+l}$。\n",
    "\n",
    "**卷积网络的神经科学基础**：卷积网络也许是生物学启发人工智能的最为成功的案例。 神经生理学家David Hubel和Torsten Wiesel观察了猫的脑内神经元如何响应投影在猫前面屏幕上精确位置的图像。 他们的伟大发现是：处于视觉系统较为前面的神经元对非常特定的光模式（例如精确定向的条纹）反应最强烈，但对其他模式几乎完全没有反应。 \n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10. Sequence Modeling: Recurrent and Recursive Nets\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Practical Methodology\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Application\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Linear Factor Models\n",
    "\n",
    "**线性因子模型（Linear Factor Models）**：线性因子模型通过随机线性解码器函数来定义，该函数通过对h的线性变换以及添加噪声来生成x。通常包含如下步骤：1.首先，我们从一个分布中采样解释性因子h，$h\\sim p(h)$，其中p(h)是一个因子分布，满足$p(h)=\\prod_i p(h_i)$；2.然后，我们对实值的可观察变量进行采样$x=Wh+b+noise$。\n",
    "\n",
    "**概率PCA、因子分析和其他线性因子模型**仅在对观测到x之前的噪声分布和隐变量h先验的选择上有所不同。\n",
    "\n",
    "**因子分析（Factor Analysis）**：隐变量先验是一个方差为单位矩阵的高斯分布$h \\sim N(h;0,I)$，同时假定在给定h的条件下观察值$x_i$是条件独立的。假设噪声是从对角协方差矩阵的高斯分布中采样的的，协方差矩阵为$ψ=diag(σ^2)$，容易看出，x服从多维正态分布，并满$x\\sim N(x;b,WW^⊤+ψ)$。\n",
    "\n",
    "**概率PCA（Probabilistic PCA）和**：在因子分析的基础上，使条件方差$σ^2_i$等于同一个值。x的协方差简化为$WW^⊤+σ^2_I$，或者等价的$x=Wh+b+σz$，其中$z\\sim N(z;0,I)$\n",
    "\n",
    "**独立成分分析（Independent Component Analysis, ICA）**：主要想法是：通过选择一个独立的p(h)，尽可能地恢复接近独立的潜在因子。每个训练样本对应一个时刻，每个$x_i$是一个传感器对混合信号的观察值，并且每个$h_i$是单个原始信号的一个估计。ICA的所有变种均要求p(h)是非高斯的。 这是因为如果p(h)是具有高斯分量的独立先验，则W是不可识别的。\n",
    "\n",
    "**慢特征分析（Slow Feature Analysis）**：是使用来自时间信号的信息学习不变特征的线性因子模型。慢特征分析的想法源于所谓的慢性原则。 其基本思想是，与场景中起描述作用的单个量度相比，场景的重要特性通常变化得非常缓慢。为了引入慢性原则，我们可以向代价函数添加以下项:$λ\\sum _tL(f(x^{(t+1)}),f(x^{(t)}))$。深度SFA已经被用于学习用在对象识别和姿态估计的特征。但是到目前为止，慢性原则尚未成为任何最先进应用的基础。究竟是什么因素限制了其性能仍有待研究，或许是慢度先验太过强势。\n",
    "\n",
    "**稀疏编码（Sparse Coding）**：是一个线性因子模型，已作为一种无监督特征学习和特征提取机制得到了广泛研究。 严格来说，术语”稀疏编码”是指在该模型中推断h值的过程，而”稀疏建模”是指设计和学习模型的过程，但是通常这两个概念都可以用术语”稀疏编码”描述。 稀疏编码模型通常假设线性因子有一个各向同性精度为β的高斯噪声：$p(x∣h)=N(x;Wh+b,\\frac{1}{β}I)$。分布p(h)通常选取为一个峰值仅在0点很尖锐的分布：$p(h_i)=Laplace(h_i;0,\\frac{2}{λ})=\\frac{λ}{4}e^{−\\frac{1}{2}λ|h_i|}$。$h^*$的表达式里包含了$||h||_1$，这导致了$h^*$向量的稀疏性。\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Autoencoders\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Representation Learning\n",
    "\n",
    "**前馈网络**：我们可以将监督学习训练的前馈网络视为表示学习的一种形式。 具体地，网络的最后一层通常是线性分类器，如softmax回归分类器。 网络的其余部分学习出该分类器的表示。\n",
    "\n",
    "**贪心逐层无监督预训练（Greddy Layer-Wise Unsupervised Pretrain）**：贪心逐层无监督预训练依赖于单层表示学习算法，例如RBM、单层自编码器、稀疏编码模型或其他学习潜在表示的模型。 每一层使用无监督学习预训练，将前一层的输出作为输入，输出数据的新的表示。 贪心逐层无监督预训练被称为贪心的，是因为它是一个贪心算法， 这意味着它独立地优化解决方案的每一个部分，每一步解决一个部分，而不是联合优化所有部分。 它被称为逐层的，是因为这些独立的解决方案是网络层。 具体地，贪心逐层无监督预训练每次处理一层网络，训练第kk层时保持前面的网络层不变。无监督预训练结合了两种不同的想法： 第一，它利用了深度神经网络对初始参数的选择，可以对模型有着显著的正则化效果（在较小程度上，可以改进优化）的想法。 第二，它利用了更一般的想法——学习输入分布有助于学习从输入到输出的映射。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/greedy_pre.png)\n",
    "从无监督预训练作为学习一个表示的角度来看，我们可以期望无监督预训练在初始表示较差的情况下更有效，一个重要的例子是词嵌入。 从无监督预训练作为正则化项的角度来看，我们可以期望无监督预训练在标注样本数量非常小时很有帮助。 大部分算法已经不使用无监督预训练了，但是在自然语言处理领域中单词作为one-hot向量的表示不能传达相似性信息，并且有非常多的未标注数据集可用。 \n",
    "\n",
    "**迁移学习（transfer learning）和领域自适应（domain adaption）**：指的是利用一个情景（例如，分布P1）中已经学到的内容去改善另一个情景（比如分布P2）中的泛化情况。 在迁移学习中，学习器必须执行两个或更多个不同的任务，但是我们假设能够解释P1变化的许多因素和学习P2需要抓住的变化相关。比如，许多视觉类别**共享**一些低级概念，比如边缘、视觉形状、几何变化、光照变化的影响等等。 在领域自适应的相关情况下，在每个情景之间任务（和最优的输入到输出的映射）都是相同的，但是输入分布稍有不同。\n",
    "\n",
    "**一次学习（one shot learning）**： 只有一个标注样本的迁移任务被称为一次学习，第一阶段学习出的表示就可以清楚地分离出潜在的类别，所以一次学习是可能的。 在迁移学习阶段，仅需要一个标注样本来推断表示空间中聚集在相同点周围许多可能测试样本的标签。\n",
    "\n",
    "**零次学习（zero shot learning）**：没有标注样本的迁移任务被称为零次学习，例子：一个学习器已经读取了大量文本，然后要解决对象识别的问题。 如果文本足够好地描述了对象，那么即使没有看到某对象的图像，也能识别出该对象的类别。 例如，已知猫有四条腿和尖尖的耳朵，那么学习器可以在没有见过猫的情况下猜测该图像中是猫。\n",
    "\n",
    "**”什么原因能够使一个表示比另一个表示更好？”**：这是表示学习的一个重要问题。一种假设是，理想表示中的特征对应到观测数据的潜在成因，特征空间中不同的特征或方向对应着不同的原因，从而表示能够区分这些原因。 \n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Structured Probabilistic Models for Deep Learning\n",
    "\n",
    "**多样化的任务**：除了分类任务以外，很多任务需要对输入数据整个结构有完整理解，包括：1.概率密度估计（Density Estimation）：给定一个输入x，机器学习系统返回一个对数据生成分布的真实密度函数p(x)的估计。 2.去噪（Denoising）：给定一个受损的或者观察有误的输入数据$\\tilde{x}$，机器学习系统返回一个对原始的真实x的估计。 3.缺失值的填补（Missing Value Imputation）：给定x的某些元素作为观察值，模型被要求返回一些或者全部未观察值的估计或者概率分布。 4.采样（Sampling）：模型从分布p(x)中抽取新的样本。\n",
    "\n",
    "**非结构化建模的挑战**：如果我们希望对一个包含n个离散变量并且每个变量都能取k个值的x的分布建模，那么最简单的表示P(x)的方法需要存储一个可以查询的表格。 这个表格记录了每一种可能值的概率，则需要$k^n$个参数。非结构化建模不可行的原因：1.内存：前面提到的存储参数的开销。 2.统计的有效性：当模型中的参数个数增加时，使用统计估计器估计这些参数所需要的训练数据数量也需要相应地增加。 因为基于查表的模型拥有天文数字级别的参数，为了准确地拟合，相应的训练集的大小也是相同级别的。 3.运行时间：推断的开销。比如推断边缘分布P(x1)或者条件分布P(x2∣x1)。 计算这样的分布需要对整个表格的某些项进行求和操作，开销也很大。 4.运行时间：采样的开销。最简单的方法就是从均匀分布中采样，u∼U(0,1)，然后把表格中的元素累加起来，直到和大于u，然后返回最后一个加上的元素。 最差情况下，这个操作需要读取整个表格。**本质问题**：基于表格操作的方法的主要问题是我们显式地对每一种可能的变量子集所产生的每一种可能类型的相互作用建模。 在实际问题中我们遇到的概率分布远比这个简单。 通常，许多变量只是间接地相互作用。\n",
    "\n",
    "**接力跑问题**：对接力跑步比赛中一个队伍完成比赛的时间进行建模。 假设这个队伍有三名成员：Alice， Bob和Carol，分别对应1/2/3棒。如果我们已经知道了Bob的完成时间，知道Alice的完成时间对估计Carol的完成时间并无任何帮助。 这意味着我们可以通过仅仅两个相互作用来建模这个接力赛。 即，我们可以忽略第三种间接的相互作用，即Alice的完成时间对Carol的完成时间的影响。\n",
    "\n",
    "**用接力跑问题分析非结构化建模的问题**：如果我们把10分钟分为100份，那么三个离散随机变量$t_1$，$t_2$，$t_3$都有100种可能值。于是，非结构化建模要表示$p(t_0,t_1,t_2)$需要保存999999种可能值。\n",
    "\n",
    "**图模型**：图模型的每个结点表示一个随机变量，每条边表示一个直接相互作用（direct interaction）。\n",
    "\n",
    "**有向图模型（Directed Graphical Model）**：有向图模型是一种结构化概率模型，也被称为信念网络（Belief Network）或者贝叶斯网络（Baysian Network）。箭头所指的方向表示了这个随机变量的概率分布是由其他变量的概率分布所定义的。 画一个从结点a到结点b的箭头表示了我们用一个条件分布来定义b，而a是作为这个条件分布符号右边的一个变量。 正式地说，变量x的有向概率模型是通过有向无环图G和一系列局部条件概率分布$p(x_i∣Pa_G(x_i))$来定义的，其中$Pa_G(x_i)$表示结点$x_i$的所有父结点。 x的概率分布可以表示为$p(x)=\\underset{i}{∏}p(x_i∣Pa_G(x_i))$。通常意义上说，对每个变量都能取k个值的n个变量建模，基于建表的方法需要的复杂度是$O(k^n)$。 但如果用一个有向图模型来对这些变量建模：m代表图模型的单个条件概率分布中最大的变量数目（包括在条件符号的左和右），那么对这个有向模型建表的复杂度大致$O(k^m)$。 只要我们在设计模型时使其满足$m≪n$，那么复杂度就会被大大地减小。\n",
    "\n",
    "**有向图模型描述接力跑问题**：$p(t_0,t_1,t_2)=p(t_0)p(t_1∣t_0)p(t_2∣t_1)$。那么，记录$t_0$的分布需要存储99个值，给定$t_0$情况下$t_1$的分布需要存储9900个值，给定$t_1$情况下$t_2$的分布也需要存储9900个值。 加起来总共需要存储19,899个值。 这意味着使用有向图模型将参数的个数减少了超过50倍！\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/race.png)\n",
    "\n",
    "**感冒生病问题**：你是否生病，你的同事是否生病以及你的室友是否生病。\n",
    "\n",
    "**无向图模型（Undirected Graphical Model）**：无向模型，也被称为马尔可夫随机场（Markov random fields， MRFs）或者是马尔可夫网络（Markov networks）。 当相互的作用并没有本质性的指向，或者是明确的双向相互作用时，使用无向模型更加合适。 正式地说，一个无向模型是一个定义在无向模型G上的结构化概率模型。 对于图中的每一个团C，一个因子（factor）$ϕ(C)$(也称为团势能)，衡量了团中变量每一种可能的联合状态所对应的密切程度。这些因子都被限制为是非负的。 它们一起定义了未归一化概率函数：$\\tilde{p}(x)=_{C∈G}ϕ(C)$。 只要所有团中的结点数都不大，那么我们就能够高效地处理这些未归一化概率函数\n",
    "\n",
    "**无向图描述感冒生病问题**：假设你的室友和同事并不认识，所以他们不太可能直接相互传染一些疾病，比如说感冒。 这个事件太过罕见，所以我们不对此事件建模。 然而，很有可能其中之一将感冒传染给你，然后通过你再传染给了另一个人。你健康状况的随机变量记作$h_y$，对应你的室友健康状况的随机变量记作$h_r$，你的同事健康的变量记作$h_c$。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/cold.png)\n",
    "因子（团势能）：\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/factor.png)\n",
    "\n",
    "**配分函数（Partition Function）**：因为$\\tilde{p}(x)$是为归一化的概率，于是$p(x)=\\frac{1}{Z}\\tilde{p}(x)$。 归一化常数Z被称作是配分函数，是关于参数Θ的函数，这是一个从统计物理学中借鉴的术语。 由于Z通常是由对所有可能的x状态的联合分布空间求和或者求积分得到的，它通常是很难计算的。 在深度学习中，ZZ通常是难以处理的。 由于ZZ难以精确地计算出，我们只能使用一些近似的方法。\n",
    "\n",
    "**基于能量的模型（Energy-Based-Models）**：无向模型中许多有趣的理论结果都依赖于$∀x, \\tilde{p}(x)>0$，这个假设。 使这个条件满足的一种简单方式是使用基于能量的模型，其中$\\tilde{p}(x)=exp(−E(x))$,E(x)被称作是能量函数。 对所有的z，exp⁡(z)都是正的，这保证了没有一个能量函数会使得某一个状态x的概率为0。 服从上面形式的任意分布都是玻尔兹曼分布的一个实例，基于这个原因，我们把许多基于能量的模型称为玻尔兹曼机。\n",
    "\n",
    "**分离（seperation）和d-分离（d-seperation）**：图模型中的边告诉我们哪些变量直接相互作用。 同时，我们经常需要知道哪些变量间接相互作用。 也就是说，我们想知道在给定其他变量子集的值时，哪些变量子集彼此条件独立。 **分离（seperation）**：如果图结构显示给定变量集S的情况下变量集A与变量集B无关，那么我们声称给定变量集S时，变量集A与另一组变量集B是分离的。 连接两个变量a和b的连接路径**仅涉及未观察变量**，那么这些变量不是分离的。 如果它们之间没有路径，或者所有路径都包含可观测的变量，那么它们是分离的。 仅涉及未观察到的变量的路径是”活跃”（active）的，而包括可观察变量的路径称为”非活跃”（inactive）的。**d-分离（d-seperation）**：“d”代表”依赖”的意思；有向图中d-分离的定义与无向模型中分离的定义相同：如果图结构显示给定变量集S时，变量集A与变量集B无关，那么我们认为给定变量集S时，变量集Ad-分离于变量集B。 如果两个变量之间存在活跃路径，则两个变量是依赖的，如果没有活跃路径，则为d-分离。 在有向网络中，确定路径是否活跃有点复杂。\n",
    "\n",
    "**判断有向图路径是否活跃的细节**：两个变量之间存在活跃路径的四中情况：![](https://raw.githubusercontent.com/applenob/reading_note/master/res/d-sep.png)\n",
    "下图中：a和b是d-seperated；给定c时，a和e是d-seperated；给定c时，d和e是d-seperated。给定c，a和b不是d-seperated；给定d，a和b不是d-seperated。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/d-sep-2.png)\n",
    "\n",
    "**有向模型到无向模型**：有向模型能够使用一种无向模型无法完美表示的特定类型的子结构，这个子结构被称为不道德（immorality）。 这种结构出现在当两个随机变量a和b都是第三个随机变量c的父结点，并且不存在任一方向上直接连接a和b的边时。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/d2ud.png)\n",
    "\n",
    "**无向模型到有向模型**：无向模型也可能包括有向模型不能完美表示的子结构：如果U包含长度大于3的环（loop），则有向图D不能捕获无向模型U所包含的所有条件独立性，除非该环还包含弦（chord）。 环指的是由无向边连接的变量序列，并且满足序列中的最后一个变量连接回序列中的第一个变量。 弦是定义环序列中任意两个非连续变量之间的连接。 如果U具有长度为4或更大的环，并且这些环没有弦，我们必须在将它们转换为有向模型之前添加弦。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/ud2d.png)\n",
    "\n",
    "**因子图（Factor Graphs）**：因子图是从无向模型中抽样的另一种方法，它可以解决标准无向模型语法中图表达的模糊性。 些节点被绘制为圆形。 就像在标准无向模型中一样，这些节点对应于随机变量。 其余节点绘制为**方块**。 这些节点对应于未归一化概率函数的因子ϕ。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/factor-model.png)\n",
    "\n",
    "**图模型的采样（Sampling）**：有向图模型的采样比较简单，称为**“原始采样”（ancestral sampling）**。始采样的基本思想是将图中的变量$x_i$使用拓扑排序，使得对于所有i和j， 如果$x_i$是$x_j$的一个父亲结点，则j大于i。 然后可以按此顺序对变量进行采样。 换句话说，我们可以首先采$x_1\\sim P(x_1)$，然后采$x_2\\sim P(x_2∣Pa_G(x_2))$，以此类推，直到最后我们从$P(x_n∣Pa_G(x_n))$中采样。从无向模型中抽取样本是一个成本很高的多次迭代的过程。 理论上最简单的方法是**Gibbs采样**。\n",
    "\n",
    "**结构化概率模型的深度学习方法**：在图模型中，我们可以根据图模型的图而不是计算图来定义模型的深度。 如果从潜变量$h_i$到可观察变量的最短路径是j步，我们可以认为潜变量$h_j$处于深度j。 我们通常将模型的深度描述为任何这样的$h_j$的最大深度。 深度学习模型通常具有比可观察变量更多的潜变量。 潜变量的设计方式在深度学习中也有所不同。 另一个明显的区别是深度学习方法中经常使用的连接类型。 深度图模型通常具有大的与其他单元组全连接的单元组，使得两个组之间的相互作用可以由单个矩阵描述。 在深度学习中使用的模型倾向于将每个可见单元$v_i$连接到非常多的隐藏单元$h_j$上，从而使得h可以获得一个$v_i$的分布式表示。 最后，图模型的深度学习方法的一个主要特征在于对未知量的较高容忍度。 \n",
    "\n",
    "**图模型举例：受限玻尔兹曼机（Restricted Boltzmann Machine）简介**：具体关于rbm的内容在第20章笔记。 标准的RBM是具有二值的可见和隐藏单元的基于能量的模型，其能量函数为：$E(v,h)=−b^⊤v−c^⊤h−v^⊤Wh$，其中b,c和W都是无约束、实值的可学习参数。 模型的一个重要方面是在任何两个可见单元之间或任何两个隐藏单元之间没有直接的相互作用（从图上理解即横向没有连线，因此称为”受限”）。 因此，有良好的性质$p(h∣v)=∏_ip(h_i∣v)$，以及$p(v∣h)=∏_ip(v_i∣h)$。 对于二元的受限玻尔兹曼机，我们可以得到：\n",
    "$p(h_i=1∣v)=σ(v^⊤W:,i+b_i),p(h_i=0∣v)=1−σ(v^⊤W_{:,i}+b_i)$\n",
    "![]()\n",
    "\n",
    "****\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Monte Carlo Methods\n",
    "\n",
    "**随机算法**：随机算法可以粗略地分为两类：拉斯维加斯算法（Las Vegas algorithms）和蒙特卡洛算法（Monte Carlo algorithms）。 \n",
    "\n",
    "**拉斯维加斯算法（Las Vegas algorithms）**：总是精确地返回一个正确答案（或者返回算法失败）。 该方法通常需要占用随机量的计算资源（一般指内存或运行时间）。 \n",
    "\n",
    "**蒙特卡洛算法（Monte Carlo algorithms）**：蒙特卡罗方法返回的答案具有随机大小的错误。 花费更多的计算资源（通常包括内存和运行时间）可以减少这种错误。 在任意固定的计算资源下， 蒙特卡罗算法可以得到一个近似解。\n",
    "\n",
    "**为什么要sampling？**：1.有时我们使用它加速一些很费时却易于处理的求和估计；2.有时我们用sampling去近似一个难以处理的求和或积分；3.还有一些时候，sampling就是我们的目标，例如我们想训练一个可以从训练分布采样的模型。\n",
    "\n",
    "**蒙特卡洛采样的基础（Basics of Monte Carlo Sampling）**：当求和和积分不能直接计算时，我们使用下面的idea：将求和和积分视作某个分布的期望：$s=∑_xp(x)f(x)=E_p[f(x)]$或者$s=∫p(x)f(x)dx=E_p[f(x)]$，然后用平均值去估计它：$\\hat{s_n} = \\frac{1}{n}\\sum_{i=1}^{n}f(x^{(i)})$\n",
    "\n",
    "**重要性采样（Importance Sampling）**：p(x)f(x)重写成：$p(x)f(x) = q(x)\\frac{p(x)f(x)}{q(x)}$，于是，蒙特卡洛Sampling可以转换成重要性Sampling，即从$\\hat{s_p} = \\frac{1}{n}\\sum_{i=1,x^{(i)}\\sim p}^{n}f(x^{(i)})$转换成$\\hat{s_q} = \\frac{1}{n}\\sum_{i=1,x^{(i)}\\sim q}^{n}\\frac {p(x^{(i)})f(x^{(i)})}{q(x^{(i)})}=\\frac{1}{n}\\sum_{i=1,x^{(i)}\\sim q}^{n}w(x^{(i)})f(x^{(i)})$。其中可以把$w(x)=\\frac{p(x)}{q(x)}$称为**重要性权重（importance weight）**\n",
    "\n",
    "**马尔科夫链蒙特卡洛方法**：在深度学习的内容中，有时候需要从目标分布$p_{model}(x)$中精确采样或者一个好的（方差较小的）重要采样分布q(x)，但是又有很多时候不能直接采样，比如使用无向图模型的时候。使用MCMC方法有一个前提：所有的可能状态的概率不能为0，即不可化简性（Irreducibility）。无向图使用的基于能量的模型（Energy Based Model， EBM）保证了这一点。 马尔科夫链（Markov Chain）的核心思想：从某个可取任意值的状态x出发。 随着时间的推移，我们随机地反复更新状态x。最终x成为了一个从近似p(x)中抽出的样本。在正式的定义中，马尔科夫链由一个随机状态x和一个转移分布$T(x′∣x)$定义而成，$T(x′∣x)$是一个概率分布，说明了给定状态x的情况下随机地转移到x′的概率。 运行一个马尔科夫链意味着根据转移分布$T(x′∣x)$采出的值x′来更新状态x。运行马尔科夫链直到它达到均衡分布的过程通常被称为马尔科夫链的磨合过程（burning in）。 mcmc方法抽样的两个连续的样本之间会高度相关，如果我们想要得到完全独立的样本，那么我们可以同时并行地运行多个马尔科夫链。深度学习的从业者们通常选取的马尔科夫链的数目和小批量中的样本数相近，然后从这些固定的马尔科夫链集合中抽取所需要的样本。 马尔科夫链的数目通常选为100。 还有另一个难点是我们无法预先知道马尔可夫链需要运行多少步才能到达均衡分布。 这段时间通常被称为混合时间（mixing time）。\n",
    "\n",
    "**吉布斯采样（Gibbs Sampling）**：其中在基于能量的模型中从T(x′∣x)采样是通过选择一个变量$x_i$，然后从$p_{model}$中该点关于在无向图G（定义了基于能量的模型结构）中邻接点的条件分布中采样。 只要一些变量在给定相邻变量时是条件独立的，那么这些变量就可以被同时采样。 \n",
    "\n",
    "这章可以参考之前的[另一篇关于MCMC的笔记](https://applenob.github.io/1_MCMC.html)，或者直接参考[An Introduction to MCMC for Machine Learning](http://www.cs.princeton.edu/courses/archive/spr06/cos598C/papers/AndrieuFreitasDoucetJordan2003.pdf)，这里是[中文简易翻译版](https://zhuanlan.zhihu.com/p/25610149)。\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Confronting the Partition Function\n",
    "\n",
    "**配分函数（Partition Function）**：许多概率模型（通常是无向图模型）由一个未归一化的概率分布$\\tilde{p}(x,θ)$定义。 必须通过除以配分函数Z(θ)来归一化$\\tilde{p}$，以获得一个有效的概率分布：$p(x;θ)=\\frac{1}{Z(θ)}\\tilde{p}(x;θ)$。 配分函数是未归一化概率所有状态的积分（对于连续变量）或求和（对于离散变量）：$∫\\tilde{p}(x)dx$或者$∑_x\\tilde{p}(x)$。对很多有趣的模型，以上积分或求和难以计算。 有些深度学习模型被设计成具有一个易于处理的归一化常数，或被设计成能够在不涉及计算p(x)p(x)的情况下使用。 然而，其他一些模型会直接面对难以计算的配分函数的挑战。\n",
    "\n",
    "**对数似然梯度（Log-Likelihood Gradient）**：对数似然对参数的梯度具有一项对应于配分函数的梯度：$∇_θlogp(x;θ)=∇_θlog\\tilde{p}(x;θ)−∇_θlogZ(θ)$，这是非常著名的正相（positive phase）和负相（negative phase）的分解。 对于保证所有的x都有p(x)>0的模型，我们可以用$exp(log\\tilde{p}(x))$代替$\\tilde{p}(x)$，$∇_θlogZ(θ)$可以化简成$E_{x\\sim p(x)}∇_θlog\\tilde{p}(x)$。 转换成这种形式后，我们自然可以考虑用蒙特卡洛法来近似这个期望。 在正相中，我们增大从数据中采样得到的$log\\tilde{p}(x)$。 在负相中，我们通过降低从模型分布中采样的$log\\tilde{p}(x)$来降低配分函数。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/p-n-phase.png)\n",
    "\n",
    "**基于MCMC的方法**：\n",
    "\n",
    "**朴素的MCMC算法**：该算法计算代价太高，实际上不可行。 但是是其他算法的思想基础。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/18-1.png)\n",
    "负相涉及到从模型分布中抽样，可以认为它在找模型信任度很高的点。 负相减少了这些点的概率，这些点一般被认为代表了模型不正确的信念。 还可以用“做梦”来帮助理解：我们的大脑维护了一个现实世界的概率模型。醒着的时候，当你经历真实的事件，相当于按照$\\tilde{p}(x)$的梯度去完善这个模型；做梦相当于从这个概率模型里随机抽样，当你醒来发现这是梦，就会按照$\\tilde{p}(x)$的负梯度去更新模型，因为你知道梦是假的。\n",
    "\n",
    "**对比散度（Contrastive Divergence，CD）算法**：接下来寻找计算代价更低的替代算法。 朴素的MCMC算法的计算成本主要来自每一步的**随机初始化**磨合马尔可夫链。 一个自然的解决方法是**初始化马尔可夫链为一个非常接近模型分布的分布**，从而大大减少磨合步骤。 CD算法在每个步骤中初始化马尔可夫链为采样自数据分布中的样本。 缺点：它不能抑制远离真实训练样本的高概率区域。 这些区域在模型上具有高概率，但是在数据生成区域上具有低概率，被称为虚假模态（spurious modes）。 在训练诸如RBM的浅层网络时,CD算法是很有用的；但CD算法并不直接有助于训练更深的模型。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/18-2.png)\n",
    "\n",
    "**持续性对比散度（Persistent Contrastive Divergence，PCD）算法**：又称**随机最大似然（Stochastic Maximum Likelihood，SML）**，不同于CD，它在每个梯度步骤中初始化马尔可夫链为**先前梯度步骤的状态值**。 因为每个马尔可夫链在整个学习过程中不断更新，而不是在每个梯度步骤中重新开始，马尔可夫链可以自由探索很远，以找到模型的所有峰值。 因此，SML比CD更不容易形成具有虚假模态的模型。 \n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/18-3.png)\n",
    "\n",
    "**伪似然（Pseudolikelihood）**：伪似然基于以下观察：无向概率模型中很容易计算概率的比率：$\\frac{p(x)}{p(y)}=\\frac{\\frac{1}{Z}\\tilde{p}(x)}{\\frac{1}{Z}\\tilde{p}(y)}=\\frac{\\tilde{p}(x)}{\\tilde{p}(y)}$。伪似然的目标函数使用条件概率：$∑_{i=1}^nlogp(x_i∣x_{−i})$。如果每个随机变量有k个不同的值，那么考虑边缘概率的计算，$\\tilde{p}$需要k×n次估计，而计算配分函数需要$k^n$次估计。\n",
    "\n",
    "**得分匹配（Score Matching）**：对数密度关于参数的导数$∇_xlogp(x)$，被称为其得分（Score）。$L(x, \\theta) = \\frac{1}{2} || ∇_x \\log p_{model}(x; \\theta) - ∇_x log p_{data} (x) ||_2^2$，用下面的式子估计：$ \\tilde{L}(x,\\theta)=\\sum_{j=1}^n(\\frac{\\partial^2}{\\partial x^2_j}logp_{model}(x;\\theta)+\\frac{1}{2}(\\frac{\\partial }{\\partial x_j}logp_{model}(x;\\theta))^2 )$\n",
    "\n",
    "**比率匹配（Ratio Matching）**：比率匹配特别适用于二值数据。 比率匹配最小化以下目标函数在样本上的均值：$L^{(RM)}(x,θ)=∑_{j=1}{n}(\\frac{1}{1+\\frac{p_{model}(x;θ)}{p_{model}(f(x),j;θ)}}^2$。其中f(x,j)返回j处位值取反的x。 比率匹配使用了与伪似然估计相同的策略来绕开配分函数：配分函数会在两个概率的比率中抵消掉。\n",
    "\n",
    "**去噪得分匹配（Denoising Score Matching）**：可以去拟合正则化的$p_{smoothed}(x)=∫p_{data}(y)q(x∣y)dy$，而不是拟合真实分布$p_{data}$。 分布q(x∣y)是一个损坏过程，通常在形成x的过程中会向y中添加少量噪声。\n",
    "\n",
    "**噪声对比估计（Noise-Contrastive Estimation，NCE）**：噪声对比估计直接估计模型的概率分布：$\\log p_{model} (x) = \\log \\tilde{p}{model} (x; \\theta) + c$，其中c是$−logZ(θ)$的近似。 噪声对比估计过程将c视为另一参数，使用相同的算法同时估计θ和c。 NCE将估计p(x)的无监督学习问题转化为学习一个概率二元分类器，其中一个类别对应模型生成的数据，另一个对应噪声生成的数据。 具体地：我们引入噪声分布$p_{noise}(x)$。 噪声分布应该易于估计和从中采样。 再构造一个联合x和新二值变量y的模型。 指定：$p_{joint}(y=1)=\\frac{1}{2}$，有$p_{joint}(x∣y=1)=p_{model}(x)$和$p_{joint}(x∣y=0)=p_{noise}(x)$\n",
    "\n",
    "**直接估计配分函数**：当我们需要评估模型，监控训练性能，和比较模型时，还是需要直接估计配分函数，我们可以考虑蒙塔卡洛的方法去估计它。 首先找到一个简单的提议分布（proposal distribution）：$p_0(x)=\\frac{1}{Z_0}\\tilde{p}_0(x)$，其在配分函数$Z_0$和未归一化分布$\\tilde{p}_0(x)$上易于采样和估计。 那么：$Z_1=∫\\tilde{p}_1(x)dx=∫\\frac{p_0(x)}{p_0(x)}\\tilde{p}_1(x)dx=Z_0∫p_0(x)\\frac{\\tilde{p}_1(x)}{\\tilde{p}_0(x)dx}$，可以使用简单重要采样（importance sampling）来估计：$\\hat{Z}_1=\\frac{Z_0}{K}\\sum_{k=1}^K\\frac{\\tilde{p}_1(x^{(k)})}{\\tilde{p}_0(x^{(k)})}\\;\\;s.t.\\;:\\;x^{(k)}\\sim p_0$\n",
    "\n",
    "**退火重要采样（Annealed Importance Sampling, AIS）**：在$D_{KL}(p_0|p_1)$很大的情况下（即$p_0$和$p_1$之间几乎没有重叠），退火重要采样通过引入中间分布来缩小这种差距。 考虑分布序列$p_{η_0},…,p_{η_n}$，其中$0=η_0<η_1<⋯<η_{n−1}<η_n=1$，分布序列中的第一个和最后一个分别是p0和p1。 $\\frac{Z_1}{Z_0}$写作$\\frac{Z_1}{Z_0}=\\prod_{j=0}^{n-1} \\frac{Z_{η_{j+1}}}{Z_{η_j}}$。 如果对于所有的$0≤j≤n−10≤j≤n−1$，分布$p_{η_j}$和$p_{η_{j+1}}$足够接近，那么能够使用简单的重要采样来估计每个因子$\\frac{Z_{η_{j+1}}}{Z_{η_j}}$，然后使用这些得到$\\frac{Z_1}{Z_0}$的估计。 中间分布的一个通用和流行选择是使用目标分布p1和建议分布p0的加权几何平均：$p_{η_j}∝p^{η_j}_1p^{1−η_j}_0$。\n",
    "\n",
    "**桥式采样（Bridge Sampling）**：桥式采样依赖于单个分布$p^∗$（被称为桥），在已知配分函数的分布$p_0$和分布$p_1$之间插值。 $\\frac{Z_1}{Z_0} ≈ \\frac{\\sum_{k=1}^K \\frac{ \\tilde{p}*(x_0^{(k)}) }{ \\tilde{p}_0(x_0^{(k)}) }} {\\sum_{k=1}^K \\frac{ \\tilde{p}*(x_1^{(k)}) }{ \\tilde{p}_1(x_1^{(k)}) }} $。 最优的桥式采样是$p^{(opt)}_∗(x)∝\\frac{\\tilde{p}_0(x)\\tilde{p}_1(x)}{r\\tilde{p}_0(x)+\\tilde{p}_1(x)}$，其中$r=Z_1/Z_0$。可以从粗糙的r开始估计，然后使用得到的桥式采样逐步迭代以改进估计。\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Approximate Inference\n",
    "\n",
    "**推断（Inference）**：我们通常使用**推断**这个术语来指代给定一些其他变量的情况下计算某些变量概率分布的过程。 在深度学习中，通常我们有一系列**可见变量v**和一系列**隐变量h**。 推断困难通常是指难以计算$p(h∣v)$或其期望。 推断在最大似然学习的任务中往往是必需的。 但是，大多数具有多层隐藏变量的图模型的后验分布都很难处理。 因此需要想办法来实现**近似推断**。\n",
    "\n",
    "**面对有隐变量的概率模型的思路**：这种情况下，目标是极大化观测数据（不完全数据）v关于参数θ的对数似然函数，即最大化：$L(θ)=logp(v;θ)=log\\sum_hp(v,h;θ)=log(\\sum_zp(h|v;θ)p(v;θ))$。 或者在图模型中，为了使用最大似然估计，有：$logp(v)=E_{h\\sim p(h|v)}[logp(h,v)-logp(h|v)]$。 总之，计算推断，也就是$p(h|v)$是很有必要的。\n",
    "\n",
    "**把推断视作优化问题**：精确推断问题可以描述为一个优化问题，计算一个$logp(v;θ)$的下界**$L(v,θ,q)$**（这个下界被称为**证据下界，evidence lower bound，ELBO**，另一个常用名称是负变分自由能，negative variational free energy）：$L(v,θ,q)=log⁡p(v;θ)−D_{KL}(q(h∣v)‖p(h∣v;θ))$，其中q是关于h的一个任意概率分布。 可以化简成：$L(v,θ,q)=E_{h\\sim q}[logp(h,v)]+H(q)$。 对任意分布q的选择来说，L提供了似然函数的一个下界。 越好地近似$p(h∣v)$的分布$q(h∣v)$，得到的下界就越紧。 **将推断问题看作是找一个分布q使得L最大的过程。** \n",
    "\n",
    "**EM（Expectation Maximization）算法**：本质上，EM并不是一个近似推断算法，而是一种能够学到近似后验的算法；但是这里EM也可以解决近似推断问题。 **E步**: 令$θ^{(0)}$表示在这一步开始时的参数值。 对索引为i的训练样本$v^{(i)}$，$q(h^{(i)}∣v)=p(h^{(i)}∣v^{(i)};θ^{(0)})$。 认为q是在当前参数$θ^{(0)}$下定义的函数，也就是如果我们改变θ，那么$p(h∣v;θ)$将会相应地变化，但是$q(h∣v)$还是不变并且等于$p(h∣v;θ^{(0)})$。\n",
    "**M步**：使用选择的优化算法关于θ最大化：$∑_iL(v^{(i)},θ,q)$。\n",
    "这可以被看作通过**坐标上升（coordinate ascending）算法**来最大化L。 在第一步中，我们更新分布q来最大化L，而在另一步中，我们更新θ来最大化L。\n",
    "\n",
    "**最大后验推断（MAP）**：$h^∗=\\underset{h}{argmax}p(h∣v)$。 令分布q满足一个Dirac分布：$q(h∣v)=δ(h−μ)$。 这也意味着可以通过μ来完全控制分布q。 转换成另一个优化问题：$μ^∗=\\underset{μ}{argmax} logp(h=μ,v)$。 使用类似EM算法的学习算法，还是轮流迭代两步，一步是用MAP推断估计出$h^*$，另一步是更新θ来增大$log p(h^*,v)$。 MAP推断作为特征提取器以及一种学习机制被广泛地应用在了深度学习中，主要用于稀疏编码模型中。\n",
    "\n",
    "**变分推断和学习（Variational Inference and Learning）**：变分学习的核心思想就是我们在一个关于q的有约束的分布族上最大化L。 选择这个分布族时应该考虑到计算$E_qlogp(h,v)$的难易度。 一个典型的方法就是添加分布q如何分解的假设,一种常用的变分学习的方法是加入一些限制使得q是一个因子分布：$q(h∣v)=∏_iq(h_i∣v)$，这被称为**均值场方法（mean field approach）**。 变分方法的优点是我们**不需要为分布q设定一个特定的参数化形式。**我们设定它如何分解，之后通过解决优化问题来找出在这些分解限制下最优的概率分布。 对**离散型潜变量**来说，这意味着我们使用传统的优化技巧来优化描述分布q的有限个变量。 对**连续型潜变量**来说，这意味着我们使用一个被称为变分法的数学工具来解决函数空间上的优化问题。\n",
    "\n",
    "**离散型潜变量**： 我们定义一个分布q，在最简单的情况中，h是二值的并且我们做了均值场假定，分布q可以根据每一个$h_i$分解。 用一个向量$\\hat{h}$来表示参数化分布q，$\\hat{h}$的每一个元素都代表一个概率，即$q(h_i=1∣v)=\\hat{h}_i$。 然后就可以通过求解$\\frac{∂}{∂\\hat{h}_i}L=0$，来优化分布q。\n",
    "\n",
    "**变分的数学基础**：许多机器学习的技巧是基于寻找一个输入向量$θ∈R_n$来最小化函数$J(θ)$，使得它取到最小值。 这个步骤可以利用多元微积分以及线性代数的知识找到满足$∇_θJ(θ)=0$的临界点来完成。 在某些情况下，我们希望能够解一个函数f(x)，比如当我们希望找到一些随机变量的概率密度函数时，借助变分法能够让我们完成这个目标。 函数f的函数被称为泛函 $J[f]$。 **泛函导数**：即在任意特定的x值，对一个泛函$J[f]$是关于函数f(x)的导数，这也被称为变分导数。 泛函J的关于函数f在点x处的泛函导数被记作$\\frac{δ}{δf(x)}J$。 对于可微分函数f(x)以及带有连续导数的可微分函数g(y,x)，有：$\\frac{δ}{δf(x)}∫g(f(x),x)dx=\\frac{∂}{∂y}g(f(x),x)$。 为了使上述等式更加直观，我们可以把f(x)看作是一个有着无穷不可数多元素的向量，由一个实数向量x作为索引。 这种关系式中描述的泛函导数和对向量$θ∈R_n$的导数相同：$\\frac{∂}{∂θ_i}∑_jg(θ_j,j)=\\frac{∂}{∂θ_i}g(θ_i,i)$。 \n",
    "\n",
    "**用变分法求解满足最大熵的分布**：考虑寻找一个定义在$x∈R$上的有最大微分熵的概率密度函数。 熵的定义（连续变量）：$H[p]=−∫p(x)logp(x)dx$。 约束：1.分布p(x)积分值为1；2.方差固定为$σ^2$；3.分布的均值必须为μ。\n",
    "\n",
    "有：$L[p]=λ_1(∫p(x)dx−1)+λ_2(E[x]−μ)+λ_3(E[(x−μ)^2]−σ^2)+H[p]=∫(λ_1p(x)+λ_2p(x)x+λ_3p(x)(x−μ)^2−p(x)logp(x))dx−λ_1−μλ_2−σ^2λ_3$ 令泛函导数为0：$∀x, \\frac{δ}{δp(x)}L=λ_1+λ_2x+λ_3(x−μ)^2−1−logp(x)=0$，解得$p(x)=exp(λ_1+λ_2x+λ_3(x−μ)^2−1)$，令$λ_1=1−logσ\\sqrt{2π}, λ_2=0, λ_3=−\\frac{1}{2σ^2}$，从而得到$p(x)=N(x;μ,σ^2)$。 这也是当我们不知道真实的分布时总是使用正态分布的一个原因。 因为正态分布拥有最大的熵。\n",
    "\n",
    "**连续型潜变量**：应用者不需要解决任何变分法的问题，均值场固定点迭代更新有一个通用的方程： 先做均值场近似：$q(h∣v)=∏_iq(h_i∣v)$，\n",
    "并且对任何的$j≠i$固定$q(h_j∣v)$，只需要满足分布p中任何联合分布变量的概率值不为0，我们就可以通过归一化下面这个未归一的分布:\n",
    "$\\tilde{q}(h_i∣v)=exp(E_{h_{−i}\\sim q(h_{−i}∣v)}log\\tilde{p}(v,h))$，来得到最优的$q(h_i∣v)$。 \n",
    "\n",
    "**学得近似推断（Learned Approximate Inference）**：我们可以将优化过程视作将一个输入v映射到一个近似分布$q^∗=\\underset{q}{argmax} L(v,q)$的一个函数f。 这样，我们就可以用一个近似函数为$\\hat f(v;θ)$的神经网络来近似它。\n",
    "\n",
    "**醒眠算法（Wake-Sleep Algorithm）**：训练一个可以用v来推断h的模型的主要难在我们没有监督训练集来训练模型。 给定一个v，无法获知一个合适的h。 醒眠算法通过从模型分布中抽取v和h的样本来解决这个问题：如在有向模型中，执行从h开始并在v结束的原始采样v和h；然后这个推断网络可以被训练来执行反向的映射：预测哪一个h产生了当前的v。 再用生物做梦来帮助理解：做梦的作用是训练网络来预测q；清醒的时候更新θ。这解释了动物如何能够保持清醒几个小时（它们清醒的时间越长，L和$logp(v)$之间的差距越大， 但是L仍然是下限）。\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Deep Generative Models \n",
    "\n",
    "**玻尔兹曼机（Boltzmann Machines）**：我们在d维二值随机向量$x∈\\{0,1\\}^d$上定义玻尔兹曼机：玻尔兹曼机是一种基于能量的模型，意味着我们可以使用能量函数定义联合概率分布： $P(x) = \\frac{\\exp(-E(x))}{Z}$，其中E(x)是能量函数，Z是确保$∑_xP(x)=1$的配分函数。 玻尔兹曼机的能量函数如下给出： $E(x) = -x^TUx - b^Tx$，其中U是模型参数的“权重”矩阵，b是偏置向量。 带隐变量的玻尔兹曼机：$E(v,h)=−v^⊤Rv−v^⊤Wh−h^⊤Sh−b^⊤v−c^⊤h$。 \n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/rbms.png)\n",
    "a是受限玻尔兹曼机，RBM；b是深度信念网络，DBN；c是深度玻尔兹曼机，DBM。\n",
    "\n",
    "**Hebbian学习规则**：我们可以假定，反射活动的持续与重复会导致神经元稳定性的持久性提升。 当神经元A的轴突与神经元B很近并参与了对B的重复持续的兴奋时，这两个神经元或其中一个便会发生某些生长过程或代谢变化，致使A作为能使B兴奋的细胞之一，它的效能增强了。 这一理论经常会被总结为“一起激发的神经元连在一起”（Cells that fire together, wire together）。这段摘自wikipedia。\n",
    "\n",
    "**受限玻尔兹曼机（Restricted Boltzmann Machine）**：其能量函数为：$E(v,h)=−b^⊤v−c^⊤h−v^⊤Wh$，“受限”在于同层之间没有连接。 使用训练具有难以计算配分函数的模型的技术来训练RBM。 这包括CD,SML（PCD）,比率匹配等。 与深度学习中使用的其他无向模型相比，因为我们可以以闭解形式计算P(h∣v)，RBM可以相对直接地训练。 \n",
    "\n",
    "**深度信念网络（Deep Belief Networks）**：目前使用较少，但历史地位突出。 特点：顶部两层之间的连接是无向的。 而所有其他层之间的连接是有向的，箭头指向最接近数据的层。 一个具有l个隐藏层的DBN包含l个权重矩阵：$W^{(1)},…,W^{(l)}$。 同时也包含l+1个偏置向量： $b^{(0)},…,b^{(l)}$，其中$b^{(0)}$是可见层的偏置。 DBN表示的概率分布由下式给出： $P(h^{(l)}, h^{(l-1)}) ∝ exp ( b^{(l)^T}h^{(l)} + b^{(l-1)^T}h^{(l-1)}+h^{(l-1)^T}W^{(l)}h^{(l)} )$，$P(h_i^{(k)} = 1 | h^{(k+1)}) = \\sigma ( b_i^{(k)} + W_{:,i}^{(k+1)^T}h^{(k+1)} )~ \\forall i, \\forall k \\in 1, ..., l-2$，  $P(v_i = 1 | h^{(1)}) = \\sigma ( b_i^{(0)} + W_{:,i}^{(1)^T}h^{(1)})~ \\forall i $。 在实值可见单元的情况下，替换$v∼N(v;b(0)+W(1)^⊤h(1),β−1)$。 采样：先在顶部的两个隐藏层上运行几个Gibbs采样；再对后面的有向图进行ancestral采样。 \n",
    "\n",
    "**深度玻尔兹曼机（Deep Boltzmann Machines）**：特点：与DBN不同的是，它是一个完全无向的模型；与RBM不同的是，它有几层潜变量（RBM只有一层）。 在一个深度玻尔兹曼机包含一个可见层v和三个隐藏层$h^{(1)},h^{(2)}和h^{(3)}$（$h^{(1)}$最靠近底层的可见层）的情况下，联合概率由下式给出：\n",
    "$P(v,h^{(1)},h^{(2)},h^{(3)})=\\frac{1}{Z(θ)}exp(−E(v,h^{(1)},h^{(2)},h^{(3)};θ))$。能量函数：$E(v, h^{(1)},h^{(2)},h^{(3)}; \\theta) = -v^T W^{(1)}h^{(1)}-h^{(1)T}W^{(2)}h^{(2)}- h^{(2)T}W^{(3)}h^{(3)}$。 条件概率：$P(v_i=1|h^{(1)})=σ(W_{i,:}^{(1)})$，$P(h_i^{(1)}|v,h^{(2)})=σ(v^TW_{:,i}^{(1)}+W_{i,:}^{(2)}h^{(2)})$，$P(h_k^{(2)}=1|h^{(1)})=σ(h^{(1)T}W_{:,k}^{(2)})$。 二分图结构使Gibbs采样能在深度玻尔兹曼机中高效采样。 有趣的性质：使用适当的均匀场允许DBM的近似推断过程捕获**自顶向下反馈**相互作用的影响。 这从神经科学的角度来看是有趣的，人脑使用许多自上而下的反馈连接。 DBM的一个**缺点**是采样时所有层都要使用MCMC。 **均匀场估计**：对于两层隐层的DBM，令$Q(h^{(1)},h^{(2)}∣v)$为$P(h^{(1)},h^{(2)}∣v)$的近似。 均匀场假设意味着$Q(h^{(1)},h^{(2)}∣v)=∏_jQ(h^{(1)}_j∣v)∏_kQ(h^{(2)}_k∣v)$。 将Q作为Bernoulli分布的乘积进行参数化：对于每个j，有$\\hat h^{(1)}_j=Q(h^{(1)}_j=1∣v)$，其中$\\hat h^{(1)}_j∈[0,1]$；对于每个k，有$\\hat h^{(2)}_k=Q(h^{(2)}_k=1∣v)$，其中$\\hat h^{(2)}_k∈[0,1]$。 $Q(h^{(1)},h^{(2)}∣v)=∏_jQ(h^{(1)}_j∣v)∏_kQ(h^{(2)}_k∣v)=∏_j(\\hat h^{(1)}_j)^{h^{(1)}_j}(1−\\hat h^{(1)}_j)^{(1−h^{(1)}_j)}×∏_k(\\hat h^{(2)}_k)^{h^{(2)}_k}(1−\\hat h^{(2)}_k)^{(1−h^{(2)}_k)}$。 更新规则：$\\hat h_j^{(1)} = \\sigma \\Big( \\sum_i v_i W_{i,j}^{(1)}+\\sum_{k'}W_{j,k'}^{(2)} \\hat h_{k'}^{(2)} \\Big), ~~~~\\forall j$和$\\hat h_{k}^{(2)} = \\sigma \\Big( \\sum_{j'} W_{j',k}^{(2)} \\hat h_{j'}^{(1)} \\Big), ~~~~\\forall k$。 **参数学习**：变分随机最大似然算法：![](https://raw.githubusercontent.com/applenob/reading_note/master/res/20-1.png)**逐层预训练**：用于分类MNIST的DBM的训练：(a)使用CD近似最大化$\\log P(v)$来训练RBM。(b)训练第二个RBM，使用CD-k近似最大化$\\log P(h^{(1)}, y)$来建模$h^{(1)}$和目标类y，其中$h^{(1)}$采自第一个RBM条件于数据的后验。在学习期间将$k$从$1$增加到$20$。(c)将两个RBM组合为DBM。使用$k = 5$的随机最大似然训练，近似最大化$\\log P(v, y)$。(d)将y从模型中删除。定义新的一组特征$h^{(1)}$和$h^{(2)}$。使用随机梯度下降和Dropout训练MLP近似最大化$\\log P(y|v)$。![](https://raw.githubusercontent.com/applenob/reading_note/master/res/layer-pre.png)**联合训练深度玻尔兹曼机**：![](https://raw.githubusercontent.com/applenob/reading_note/master/res/jointly-train.png)\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
