{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 《Deep Learning》\n",
    "\n",
    "![](https://img3.doubanio.com/lpic/s29133163.jpg)\n",
    "\n",
    "## 目录\n",
    "\n",
    "- [0.书本介绍](#0.书本介绍)\n",
    "- [1. Introduction](#1.-Introduction)\n",
    "- [2. Linear Algebra](#2.-Linear-Algebra)\n",
    "- [3. Probability and Information Theory](#3.-Probability-and-Information-Theory)\n",
    "- [4. Numerical Computation](#4.-Numerical-Computation)\n",
    "- [5. Machine Learning Basics](#5.-Machine-Learning-Basics)\n",
    "- [6. Deep Feedforward Networks](#6.-Deep-Feedforward-Networks)\n",
    "- [7. Regularization for Deep Learning](#7.-Regularization-for-Deep-Learning)\n",
    "- [8. Optimization for Training Deep Models](#8.-Optimization-for-Training-Deep-Models)\n",
    "- [9. Convolutional Networks](#9.-Convolutional-Networks)\n",
    "- [10. Sequence Modeling: Recurrent and Recursive Nets](#10.-Sequence-Modeling:-Recurrent-and-Recursive-Nets)\n",
    "- [11. Practical Methodology](#11.-Practical-Methodology)\n",
    "- [12. Application](#12.-Application)\n",
    "- [13. Linear Factor Models](#13.-Linear-Factor-Models)\n",
    "- [14. Autoencoders](#14.-Autoencoders)\n",
    "- [15. Representation Learning](#15.-Representation-Learning)\n",
    "- [16. Structured Probabilistic Models for Deep Learning](#16.-Structured-Probabilistic-Models-for-Deep-Learning)\n",
    "- [17. Monte Carlo Methods](#17.-Monte-Carlo-Methods)\n",
    "- [18. Confronting the Partition Function](#18.-Confronting-the-Partition-Function)\n",
    "- [19. Approximate](#19.-Approximate)\n",
    "- [20. Deep Generative Models](#20.-Deep-Generative-Models)\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "## 0.书本介绍\n",
    "\n",
    "[Deep Learning](https://book.douban.com/subject/26883982/)\n",
    "\n",
    "[原版阅读网站](http://www.deeplearningbook.org/)\n",
    "\n",
    "作者:  Ian Goodfellow / Yoshua Bengio / Aaron Courville \n",
    "\n",
    "内容简介：\n",
    "\n",
    "```\n",
    "\"Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.\" -- Elon Musk, co-chair of OpenAI; co-founder and CEO of Tesla and SpaceX\n",
    "Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning.\n",
    "The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models.\n",
    "Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.\n",
    "```\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "什么是**machine learning**? \n",
    "\n",
    "在原始的AI系统中，定义不同的case使用不同的解决方法，这称为“hard code”。进一步的AI系统需要一种去获取知识的能力，也就是从原始数据中发现模式（“Pattern”），这种能力就是**machine learning**。\n",
    "\n",
    "但是，一般的machine learning算法严重依赖于数据的**表示(representation)**，表示中包含的每份信息又称为**feature**。\n",
    "\n",
    "这又引发了一个新的问题，对于很多task，我们不知道应该提取什么样的特征（只能经验主义）。\n",
    "\n",
    "于是又有了**representation learning**，即使用machine learning不光光是学习reprsentation到output的映射（mapping），还要学习data到representation的映射。\n",
    "\n",
    "典型的表示学习算法是**autoencoder**。encoder函数是将输入数据映射成表示;decoder函数将表示映射回原始数据的格式。\n",
    "\n",
    "representation learning的难点：表示是多种多样的，一种表示学习算法很难覆盖多种层次和不同类型的表示。\n",
    "\n",
    "**Deep Learning**：使用多层次的结构，用简单的表示来获取高层的表示。这样，解决了上面的问题（一种方法）。\n",
    "\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/dl.png)\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "## 2. Linear Algebra\n",
    "\n",
    "- Scalars: 一个数；\n",
    "\n",
    "- Vctors: 一列数；\n",
    "\n",
    "- Matrices: 二位数组的数，每个元素由两个下标确定；\n",
    "\n",
    "- Tensors: 多维数组的数。\n",
    "\n",
    "***\n",
    "\n",
    "**转置（transpose）**：$(A^T)_{i,j}=A_{j,i}$\n",
    "\n",
    "**矩阵乘法**: $C=AB$， $C_{i,j}=\\sum_kA_{i,k}B_{k,j}$\n",
    "\n",
    "**元素乘法(element product; Hardamard product)**：$A \\bigodot B$\n",
    "\n",
    "**点乘(dot product)**: 向量**x**，**y**的点乘：  $x^Ty$\n",
    "\n",
    "**单位矩阵(identic matrix)**: $I_n$， 斜对角的元素值是1,其他地方都是0\n",
    "\n",
    "**逆矩阵（inverse matrix）**:$A^{-1}$, $A^{-1}A=I_n$\n",
    "\n",
    "方程Ax=b，如果A可逆，则$x=A^{-1}b$\n",
    "\n",
    "**线性组合（linear combination）**：将矩阵A看作是不同的列向量的组合[d1,d2,...,dn]，每个列响亮代表一个方向，x可以代表在每个方向上移动的距离，那么Ax=b可以理解成原点如何在A指定的各个方向上移动，最后到达b点。Ax即为线性组合，组合的对象是各个列向量，方式是x的元素。\n",
    "\n",
    "**生成空间（span）**：对所有的x，生成的点Ax的集合，即为A的生成空间。\n",
    "\n",
    "**范数（Norm）**：用来衡量vector的尺寸。$L^p$ norm:\n",
    "$$||x||_p = \\left ( \\sum_i{|x_i|^p} \\right )^{\\frac{1}{p}}$$\n",
    "\n",
    "**Frobenius-norm**: 用来衡量matrix的尺寸。类似于$L_2$ norm\n",
    "$$||A||_F=\\sqrt{\\sum_{i,j}{A_{i,j}^2}}$$\n",
    "\n",
    "**对角阵（diagnal matrix）**：除了对角线上的元素不为0,其他元素都为0。可以表示为diag(v)。\n",
    "\n",
    "**对称阵（symmetric matrix）**：$A=A^T$\n",
    "\n",
    "**单位向量（unit vector）**：$||x||_2 = 1$\n",
    "\n",
    "**正交（orthogonal）**：如果$x^Ty=0$，则向量x和向量y彼此正交。\n",
    "\n",
    "**正交归一化矩阵（orthonormal matrix）**：每行都相互正交并且都是单位向量。$A^TA=AA^T=I$，有$A^{-1}=A^T$。\n",
    "\n",
    "**特征分解**：特征向量v和特征值λ，满足：$Av = λv$，方阵A可以这样分解：$A=Vdiag(λ)V^{-1}$，其中,$V=[v^{(1)},...,v^{(n)}]$,$λ=[λ_1, ..., λ_n]^T$。特别的，如果A是一个实对称阵，那么$A=Q∧Q^T$\n",
    "\n",
    "**正定（positive definite）**：一个矩阵的所有特征值都是正的，则称这个矩阵正定。\n",
    "\n",
    "**奇异值分解（singular value decomposition）**：$A = UDV^T$，其中A是m×n矩阵；U是m×m正交矩阵，U的列向量称为左奇异向量，是$AA^T$的特征向量；D是m×n对角矩阵，对角线上的元素称为奇异值；V是正交n×n矩阵，V的列向量称为右奇异向量，是$A^TA$的特征向量。\n",
    "\n",
    "**伪逆（Moore-Penrose Pseudoinverse）**：$A^+ = VD^+U^T$，其中，$D^+$是由D的每个对角线元素取倒数（reciprocal）获得。\n",
    "\n",
    "**迹（Trace）**：$Tr(A) = \\sum_i A_{i,i} $，即对角线元素之和。\n",
    "\n",
    "**行列式（Determinant）**：det(A)，是一个将一个matrix映射到一个实数的function。行列式的值等于矩阵的所有特征值的乘积。\n",
    "\n",
    "**奇异矩阵（singular matrix）**：前提是方阵，如果A(n×n)为奇异矩阵（singular matrix）<=> A的秩$Rank(A)<n$；如果A(n×n)为非奇异矩阵（nonsingular matrix）<=> A满秩，$Rank(A)=n$。\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Probability and Information Theory\n",
    "\n",
    "### 概率论部分\n",
    "\n",
    "**频率学派概率（frequentist probability）**：认为概率和事件发生的频率相关；**贝叶斯学派概率（Bayesian probability）**：认为概率是的对某件事发生的确定程度，可以理解成是确信的程度（degree of belief）。\n",
    "\n",
    "**随机变量（random variable）**：一个可能随机获取不同值的变量。\n",
    "\n",
    "**概率质量函数（probability mass function，PMF）**：用来描述离散随机变量的概率分布。表示为P(x)，是状态到概率的映射。\n",
    "\n",
    "**概率密度函数（probability density function，PDF）**：用来描述连续随机变量的概率分布，p(x)。\n",
    "\n",
    "**条件概率（conditional probability）**：$P(y=y|x=x) = \\frac{P(y=y, x=x)}{P(x=x)}$\n",
    "\n",
    "**条件概率的链式法则（chain rule of conditional probability）**：$P(x^{(1)}, ..., x^{(n)}) = P(x^{(1)})\\prod^n_{i=2}P(x^{(i)}|x^{(1)}, ..., x^{(i-1)})$\n",
    "\n",
    "**独立（independence）**：$\\forall x ∈ x, y ∈ y, p(x=x, y=y) = p(x=x)p(y=y)$\n",
    "\n",
    "**条件独立（conditional independence）**：$\\forall x ∈ x, y ∈ y, z ∈ z,p(x=x, y=y | z=z) = p(x=x | z=z)p(y=y | z=z)$\n",
    "\n",
    "**期望（expectation）**：期望针对某个函数f(x)，关于概率分布P(x)的平均值。对离散随机变量：$E_{x \\sim P}[f(x)] = \\sum_xP(x)f(x)$；对连续随机变量：$E_{x \\sim p}[f(x)] = \\int P(x)f(x)dx$。期望是线性的：$E_x[αf(x)+βg(x)] = αE_x[f(x)]+βE_x[f(x)]$\n",
    "\n",
    "**方差（variance）**：用来衡量从随机变量x的分布函数f(x)中采样出来的一系列值和期望的偏差。$Var(x) = E[(f(x)-E[f(x)])^2]$，方差开平方即为标准差（standard deviation）。\n",
    "\n",
    "**协方差（covariance）**：用于衡量两组值之间的线性相关程度。$Cov(f(x), g(y)) = E[(f(x)-E[f(x)])(g(y)-E[g(y)])]$。独立比协方差为0更强，因为独立还排除了非线性的相关。\n",
    "\n",
    "**贝努力分布（Bernoulli Distribution）**：随机变量只有两种可能的分布，只有一个参数：Φ，即x=1的概率。\n",
    "\n",
    "**多项式分布（Multinoulli Distribution）**随机变量有k种可能的分布，参数是一个长度为k-1的向量p。\n",
    "\n",
    "**高斯分布（Gaussian Distribution）**即正态分布（normal distribution），$\\textit{N}(x;μ,σ^2) = \\sqrt{\\frac{1}{2πσ^2}}exp(-\\frac{1}{2σ^2}(x-μ)^2)$。中心极限定理（central limit theorem）认为，大量的独立随机变量的和近似于一个高斯分布，这一点可以大量使用在应用中，我们可以认为噪声是属于正态分布的。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/gauss.PNG)\n",
    "\n",
    "**多元正态分布（multivariate normal distribution）**：给定协方差矩阵$\\mathbf{Σ}$（正定对称），$\\textit{N}(x;μ,Σ) = \\sqrt{\\frac{1}{(2π)^ndet(Σ)}}exp(-\\frac{1}{2}(x-μ)^TΣ^{-1}(x-μ))$\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/MultivariateNormal.png/450px-MultivariateNormal.png)\n",
    "\n",
    "**指数分布（exponential distribution）**：在深度学习的有研究中，经常会用到在x=0点获得最高的概率的分布，$p(x; λ) = λ\\mathbf{1}_{x≥0}exp(-λx)$，或者：$f(x) = \\left\\{\\begin{matrix}λexp(-λx) \\;\\;\\;\\; x≥0 \\\\0 \\;\\;\\;\\; else \\end{matrix}\\right.$，其中λ > 0是分布的一个参数，常被称为率参数（rate parameter）。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/exp_dis.png)\n",
    "\n",
    "**拉普拉斯（Laplace Distribution）**：另一个可以在一个点获得比较高的概率的分布。$Laplace(x ;μ,γ) = \\frac{1}{2γ}exp(-\\frac{|x-μ|}{γ})$\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/laplace.jpg)\n",
    "\n",
    "**迪拉克分布（Dirac Distribution）**：$p(x) = δ(x-μ)$，这是一个泛函数。迪拉克分布经常被用于组成经验分布（empirical distribution）：$p(x) = \\frac{1}{m}\\sum_{i=1}^m{δ(x-x^{(i)})}$\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/dirac.png)\n",
    "\n",
    "**逻辑斯蒂函数（logistic function）**：$σ(x) = \\frac{1}{1+exp(-x)}$，常用来生成贝努力分布的Φ参数。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/logistic.png)\n",
    "\n",
    "**softplus function**: $ζ(x) = log(1+exp(x))$，是“取正”函数的“soft”版：$x^+ = max(0, x)$\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/softplus.png)\n",
    "\n",
    "**贝叶斯公式（Bayes' Rule）**：$P(x|y) = \\frac{P(x)P(y|x)}{P(y)}$\n",
    "\n",
    "### 信息论部分\n",
    "\n",
    "**信息论背后的直觉： 学习一件不太可能的事件比学习一件比较可能的事件更有信息量。**\n",
    "\n",
    "**信息（information）需要满足的三个条件**：1.比较可能发生的事件的信息量要少；2.比较不可能发生的事件的信息量要大；3.独立发生的事件之间的信息量应该是可以叠加的。\n",
    "\n",
    "**自信息（self-information）：**对事件x=x，$I(x) = -logP(x)$，满足上面三个条件，单位是nats（底为e）\n",
    "\n",
    "**香农熵（Shannon entropy）**：自信息只包含一个事件的信息，对于整个概率分布p(x)，不确定性可以这样衡量：$E_{x\\sim P}[I(x)] = -E_{x\\sim P}[logP(x)]$，也可以表示成H(P)。\n",
    "\n",
    "**KL散度（Kullback-Leibler divergence）**：衡量两个分布P(x)和Q(x)之间的差距。$D_{KL}(P||Q)=E_{x\\sim P}[log \\frac{P(x)}{Q(x)}]=E_{x\\sim P}[logP(x)-logQ(x)]$，注意$D_{KL}(P||Q)≠D_{KL}(Q||P)$\n",
    "\n",
    "**交叉熵（cross entropy）**：$H(P,Q)=H(P)+D_{KL}(P||Q)=-E_{x\\sim P}[logQ(x)]$，假设P是真实分布，Q是模型分布，那么最小化交叉熵H(P,Q)可以让模型分布逼近真实分布。\n",
    "\n",
    "### 图模型（Structured Probabilistic Models）\n",
    "\n",
    "**有向图模型（Directed Model）**：$p(x) = \\prod_i p(x_i | Pa_g(x_i))$， 其中$Pa_g(x_i)$是$x_i$的父节点。举例：\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/dg.png)\n",
    "\n",
    "$P(a,b,c,d,e)=p(a)p(b|a)p(c|a,b)p(d|b)p(e|c)$\n",
    "\n",
    "**无向图模型（Undirected Model）**：所有节点都彼此联通的集合称作“团”（Clique）。$p(x)=\\frac{1}{Z}\\prod_i{Φ^{(i)}(C^{(i)})}$，其中，Φ称作facor，每个factor和一个团（clique）相对应。举例：\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/udg.png)\n",
    "\n",
    "$p(a,b,c,d,e) = \\frac{1}{Z}Φ^{(1)}(a,b,c)Φ^{(2)}(b,d)Φ^{(3)}(c,e)$\n",
    "\n",
    "****\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Numerical Computation\n",
    "\n",
    "**数值优化（Numerical Computation）**：通常指代那些在解决数学问题时，不使用从符号表达式中直接推导出解析解，而是使用迭代更新的方式获取答案的算法。\n",
    "\n",
    "**上溢和下溢（overflow/underflow）**：数据太小或者太大，在计算机内存中无法表示。\n",
    "\n",
    "**优化问题（optimization problem）**：优化目标：最小化函数：损失函数（loss function）/ 错误函数（error function）通常上标\\*表示最优解。$x^*=argmin f(x)$\n",
    "\n",
    "**临界点（critical point）**：$f'(x)=0$的点称为临界点，一般临界点取得极大值或者极小值，否则为鞍点（saddle point）。\n",
    "\n",
    "**梯度下降（gradient descent）**：$x' = x-ε\\triangledown _xf(x)$，其中，ε是学习率。\n",
    "\n",
    "**Jacobian 矩阵（Jacobian matrix）**：如果我们有一个函数f:$\\mathbb{R}^m \\rightarrow \\mathbb{R}^n$，那么Jacobian矩阵即为：$J_{i,j} = \\frac {\\partial}{\\partial x_j}f(x)_i$。\n",
    "\n",
    "**Hessian 矩阵（Hessian matrix）**：$H(f)(x)_{i,j} = \\frac {\\partial ^2}{\\partial x_i \\partial x_j}f(x)$。可以知道，Hessian矩阵是对称阵。\n",
    "\n",
    "**牛顿法（Newton's method）**：将函数用二阶的泰勒公式近似：$f(x)≈f(x^{(0)})+(x-x^{(0)})^T\\triangledown_xf(x^{(0)})+\\frac{1}{2}(x-x^{(0)})^TH(f)(x^{(0)})(x-x^{(0)})$，求解临界点$x^* = x^{(0)}-H(f)(x^{(0)})^{-1}\\triangledown_xf(x^{(0)})$。梯度下降称为“一阶优化算法”；牛顿法称为“二阶优化算法”。\n",
    "\n",
    "**KKT方法求解约束优化（constrained optimization）问题**：约束空间$\\mathbb{S}=\\{x|\\forall i, g^{(i)}(x)=0\\, and\\, \\forall j, h^{(j)}(x)\\leq 0\\}$，g称为等式约束，h称为不等式约束。引入变量$λ_i$和$α_j$，称为KKT乘子。拉格朗日函数（generalized Lagrangian）：$L(x,λ,α)=f(x)+\\sum _iλ_ig^{(i)}(x) + \\sum _jα_jh^{(j)}(x) $，则$\\underset{x}{min}\\underset{λ}{max}\\underset{α,α\\geq 0}{max}L(x,λ,α)$等价于$\\underset{x∈\\mathbb{S}}{min}f(x)$。KKT条件：1.拉格朗日函数对x,λ,α求偏导都为0；2.对于不等式约束，$α\\bigodot h(x)=\\mathbf{0}$。\n",
    "\n",
    "****\n",
    "\n",
    "****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning Basics\n",
    "\n",
    "**机器学习定义**：一个计算机程序，如果它能做到在任务T中的性能P随着经验E可以提高，那就可以称它是关于某类任务T和性能衡量P，从经验E中学习。\n",
    "\n",
    "**机器学习任务（T）类别**：分类（classification）/缺失输入数据的分类（classification with missing data）/回归（regression）/转录（transciption）/机器翻译（machine translation）/结构化输出（structured output）/异常检测（anomaly detection）/合成和采样（synthesis and smapling）/缺失值填补（imputation of missing data）/去噪（denoising）/密度估计（density estimation）\n",
    "\n",
    "**机器学习的性能（P）**：P因为T的不同而不同。对于像分类/缺失输入数据的分类/转录，使用准确率（accuracy）来衡量性能；而对于密度估计，通常输出模型在一些样本上概率对数的平均值。\n",
    "\n",
    "**机器学习的经验（E）**：根据经验的不同，分为监督学习和无监督学习。监督学习：学习p(x)；无监督学习：学习p(y|x)。通常来说，无监督学习通常指代从不需要人工标注数据中提取信息。\n",
    "\n",
    "**泛化（generalization）**：在先前未观测到的输入上表现良好的能力被称为泛化。\n",
    "\n",
    "**欠拟合（underfitting）和过拟合（overfitting）**：机器学习的性能取决于两点因素：1.使训练误差更小；2.使训练误差和测试误差的差距更小。分别对应欠拟合的改善和过拟合的改善。\n",
    "\n",
    "**模型的容量（capacity）**：模型的容量是指其拟合各种函数的能力。\n",
    "\n",
    "**VC维（Vapnik-Chervonenkis dimension）**：VC维用来度量二分类器的容量。假设存在m个不同的x点的训练集，分类器可以任意地标记该m个不同的x点，VC维即m的最大可能值。[详细解释](http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/)\n",
    "\n",
    "**奥卡姆剃刀（Occam's razor）**：在同样能够解释已知观测现象的假设中，我们应该挑选”最简单”的那一个。\n",
    "\n",
    "**没有免费的午餐定理（no free lunch theorem）**：所有分类算法在分类没有见过的点的时候，他们的错误率的期望是一样的。这个定理告诉我们，必须要针对特定的任务去设计机器学习算法。\n",
    "\n",
    "**正则化（Regularization）**：正则化是指我们针对减少泛化误差而不是训练误差，在一个机器学习算法上做的任何改动。\n",
    "\n",
    "**超参数（Hyperparameters）**：超参数的值不能通过学习算法本身学习出来。\n",
    "\n",
    "**验证集（Validation Sets）**：验证集用来调超参数。\n",
    "\n",
    "**最大似然估计（Maximum Likelihood Estimation, MLE）**：参数θ的最大似然估计：$θ_{ML} = \\underset{θ}{argmax}p_{model}(\\mathbb{X};θ) = \\underset{θ}{argmax}\\prod_{i=1}^mp_{model}(x^{(i)};θ)$。对数形式：$θ_{ML} = \\underset{θ}{argmax}\\sum_{i=1}^mlogp_{model}(x^{(i)};θ)$。是一种点估计方法。\n",
    "\n",
    "**贝叶斯统计（Bayesian Statistics）**：最大似然估计是频率学派的观点，认为参数θ是固定的，但是未知；贝叶斯统计观点认为，数据集是直接观察得到的，因此数据集不是随机的，但是参数θ是一个随机变量。$p(θ|x^{(1)},x^{(2)},...,x^{(m)}) = \\frac{p(x^{(1)},x^{(2)},...,x^{(m)}|θ)}p(θ){p(x^{(1)},x^{(2)},...,x^{(m)})}$\n",
    "\n",
    "**最大后验(Maximum A Posteriori, MAP)估计**：$θ_{MAP}=\\underset{θ}{argmax}p(θ∣x)=\\underset{θ}{argmax}logp(x∣θ)+logp(θ)$。是一种点估计方法。\n",
    "\n",
    "**机器学习算法的常见组成部分**：一个数据集（dataset）+一个损失函数（cost function）+一个优化过程（optimization procedure）+一个模型（model）\n",
    "\n",
    "**维数灾难（the Curse of Dimensionality）**：当数据的维数很高时，很多机器学习问题变得相当困难。 这种现象被称为维数灾难。\n",
    "\n",
    "**流形（manifold）学习**：流形指连接在一起的区域。 数学上，它是指一组点，且每个点都有其邻域。 给定一个任意的点，其流形局部看起来像是欧几里得空间。 日常生活中，我们将地球视为二维平面，但实际上它是三维空间中的球状流形。流形学习算法通过一个假设来克服这个障碍，该假设认为$R_n$中大部分区域都是无效的输入，有意义的输入只分布在包含少量数据点的子集构成的一组流形中，而学习函数的输出中，有意义的变化都沿着流形的方向或仅发生在我们切换到另一流形时。我们认为在人工智能的一些场景中，如涉及到处理图像、声音或者文本时，流形假设至少是近似对的。\n",
    "\n",
    "****\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deep Feedforward Networks\n",
    "\n",
    "**深度前馈网络（Deep Feedforward Networks）**：也被称为前馈神经网络（feedforward neural networks），或者多层感知机（multi-layer perceptrons， MLPs）是典型的深度学习模型。前馈网络的目标是去近似一个函数$f^*$。模型之所以称为前馈，是因为信息只向前流动，没有反馈的连接。\n",
    "\n",
    "**基于梯度的学习（Gradient Based Learning）**：神经网络模型和线性模型最大的区别在于神经网络的非线性使得损失函数不再是凸函数。这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值；而不是像用于训练线性回归模型的线性方程求解器，或者用于训练逻辑回归或~SVM~的凸优化算法那样保证全局收敛。 凸优化从任何一种初始参数出发都会收敛（理论上如此——在实践中也很鲁棒但可能会遇到数值问题）。 用于非凸损失函数的随机梯度下降没有这种收敛性保证，并且对参数的初始值很敏感。 对于前馈神经网络，将所有的权重值初始化为小随机数是很重要的。 偏置可以初始化为零或者小的正值。 \n",
    "\n",
    "**输出单元：**\n",
    "\n",
    "**1.用于高斯输出分布的线性单元（Linear Output Units）**：$\\hat y = W^Th+b$，通常用来预测条件高斯分布：$p(y|x)=N(y;\\hat y, I)$\n",
    "\n",
    "**2.用于Bernoulli输出分布的sigmoid单元（Sigmoid Output Units）**：二分类任务，可以通过这个输出单元解决。$\\hat y = σ(w^Th+b)$，其中，σ是sigmoid函数。\n",
    "\n",
    "**3.用于 Multinoulli输出分布的softmax单元（Softmax Output Units）**：$z=W^th+b$，而$softmax(z)_i=\\frac{exp(z_i)}{\\sum_jexp(z_j)}$，如果说argmax函数返回的是一个onehot的向量，那么softmax可以理解成soft版的argmax函数。\n",
    "\n",
    "**隐藏单元：**\n",
    "\n",
    "**1.修正线性单元（Rectified Linear Units，ReLU）**：使用激活函数$g(z)=max\\{0,z\\}$，有$h=g(W^Tx+b)$。通常b的初始值选一个小正值，如0.1。这样relu起初很可能是被激活的。relu的一个缺点是它不能在激活值是0的时候，进行基于梯度的学习。因此又产生了各种变体。\n",
    "\n",
    "**1.1.maxout单元：整流线性单元的一种扩展**：$g(z)_i=\\underset {j∈\\mathbb{G}(i)}{max}z_j$，其中，$\\mathbb{G}(i)$是第i组的输入索引集$\\{(i−1)k+1,…,ik\\}$。\n",
    "\n",
    "**2.logistic sigmoid与双曲正切函数（Hyperbolic Tangent）单元**：使用logistic sigmoid：$g(z)=σ(z)$；使用双曲正弦函数：$g(z)=tanh(z)$，其中, $tanh(z)=2σ(2z)-1$。 但是，在这两个函数的两端都很容易饱和，所以不鼓励用在隐藏单元中，一定要用可以优先选择双曲正弦函数。\n",
    "\n",
    "**通用近似性质（Universal Approximation Properties）**：一个前馈神经网络如果具有线性输出层和至少一层具有激活函数（例如logistic sigmoid激活函数）的隐藏层，只要给予网络足够数量的隐藏单元，它可以以任意的精度来近似任何从一个有限维空间到另一个有限维空间的Borel可测函数。 虽然具有单层的前馈网络足以表示任何函数，但是网络层可能大得不可实现，并且可能无法正确地学习和泛化。 在很多情况下，使用更深的模型能够减少表示期望函数所需的单元的数量，并且可以减少泛化误差。\n",
    "\n",
    "**MLP的深度（Depth）**：具有d个输入、深度为l、每个隐藏层具有n个单元的深度整流网络可以描述的线性区域的数量是$O(\\begin{pmatrix}\n",
    "n\\\\\n",
    "d\n",
    "\\end{pmatrix}^{d(l−1)}n^d)$,意味着，这是深度l的指数级。\n",
    "\n",
    "**后向传播算法（Back-Propagation）**：后向传播算法将偏差（cost）在网络中从后往前传播，用来计算关于cost的梯度。后向传播算法本身不是学习算法，而是学习算法，像SGD，使用后向传播算法来计算梯度。对于bp的生动理解，可以参考[知乎的这个回答](https://zhihu.com/question/27239198/answer/89853077)，“同样是利用链式法则，BP算法则机智地避开了这种冗余，它对于每一个路径只访问一次就能求顶点对所有下层节点的偏导值”；“BP算法就是主动还款。e把所欠之钱还给c，d。c，d收到钱，乐呵地把钱转发给了a，b，皆大欢喜”。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/fp.png)\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/bp.png)\n",
    "\n",
    "**计算图（Computational Graphs）**：节点代表变量（variable）；引入操作（operation）的概念，操作是一个或者多个变量的函数，如果一个变量y是由一个对于变量x的操作得来的，那么就可以画一条有向边，从x指向y；\n",
    "\n",
    "**微积分中的链式法则（Chain Rule）**：假设y=g(x)，z=f(g(x))=f(y)，那么有$\\frac{dz}{dx}=\\frac{dz}{dy}\\frac{dy}{dx}$；进一步，如果$x∈R^m，y∈R^n，g：R^m \\rightarrow R^n，f：R^n \\rightarrow R$，有$\\frac{\\partial z}{\\partial x_i}=\\sum_j \\frac{\\partial z}{\\partial y_j}\\frac{\\partial y_j}{\\partial x_i}$，可以写成向量形式：$\\triangledown _xz(\\frac{\\partial y}{\\partial x})^T\\triangledown _yz$，其中，$\\frac{\\partial y}{\\partial x}$是n×m的g的Jacobian矩阵。\n",
    "\n",
    "**不同框架的bp实现**：1.\"symbol-to-number\"：以计算图和数值作为图的输入，返回一系列数值，作为输入的梯度。**Torch**，**Caffe**。2.\"symbol-to-symbol\"：以计算图作为输入，开辟额外的图，来保存需要的微分的符号表示。这种方法可以在学习算法中多次使用，并且可以用来计算更高阶的微分。\n",
    "\n",
    "****\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Regularization for Deep Learning\n",
    "\n",
    "**正则化（Regularization）**：对学习算法的修改——旨在减少泛化误差而不是训练误差。\n",
    "\n",
    "**参数范数惩罚（Parameter Norm Penalties）**：通过对目标函数J添加一个**参数范数惩罚Ω(θ)**，来限制模型的学习能力。 我们将正则化后的目标函数记为\\tilde{J}：$\\tilde{J}(θ;X,y)=J(θ;X,y)+αΩ(θ)$，其中α∈[0,∞)是权衡范数惩罚项Ω和标准目标函数 J(X;θ)相对贡献的超参数。说明，在神经网络中我们通常只对每一层仿射变换的**权重w**做惩罚而不对偏置做正则惩罚。典型的参数范数惩罚有$L^2$参数正则和$L^1$参数正则。\n",
    "\n",
    "**$L^2$参数正则（$L^2$ Parameter Regularization）**：也就是**权重衰减（weight decay）**，罚项为$Ω(θ)=\\frac{1}{2}||w||_2^2$，也称为岭回归（ridge regression）或Tikhonov正则。 在训练过程中，只有在显著减小目标函数方向上的参数会保留得相对完好；在无助于目标函数减小的方向（对应~Hessian~矩阵较小的特征值）上改变参数不会显著增加梯度。 这种不重要方向对应的分量会在训练过程中因正则化而衰减掉。\n",
    "\n",
    "**$L^1$参数正则（$L^1$ Parameter Regularization）**：罚项为$Ω(θ)=||w||_1=\\sum_i|w_i|$，相比于$L^2$正则，$L^1$正则产生更多的稀疏性结果，此处稀疏性指的是最优值中的一些参数为0。这一性质也使得$L^1$正则在**特征选择**机制中被广泛使用。\n",
    "\n",
    "**作为约束的范数惩罚**：我们可以把参数范数惩罚看作对权重强加的约束。 如果Ω是$L^2$范数，那么权重就是被约束在一个$L^2$球中。 如果Ω是$L^1$范数，那么权重就是被约束在一个$L^1$范数限制的区域中。 \n",
    "\n",
    "**数据集增强（Dataset Augmentation）**：实际上，让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练。 但在实践中，我们拥有的数据量是很有限的。 解决这个问题的一种方法是创建假数据并添加到训练集中。这种方法用在分类任务来说是很简单的； 但这种方法对于其他许多任务来说并不那么容易，比如密度估计问题。 数据集增强在目标识别（objective recognition）和语音识别（speech recognition）上被证实比较有效。通常情况下，人工设计的数据集增强方案可以大大减少机器学习技术的泛化误差。\n",
    "\n",
    "**噪声鲁棒性（Noise Robustness）**：噪声可以直接注入到输入数据，作为数据集增强，向输入添加方差极小的噪声等价于对权重施加范数惩罚；也可以向隐藏单元添加噪声，这种罚项更加强大；可以直接向权重w注入噪声，经常用于rnn，它推动模型进入对权重小的变化相对不敏感的区域，找到的点不只是极小点，还是由平坦区域所包围的最小点；还可以向输出目标注入噪声，比如label smoothing。\n",
    "\n",
    "**半监督学习（Semi-Supervised Learning）**：在深度学习的背景下，半监督学习通常指的是学习一个表示：h=f(x)。 学习表示的目的是使相同类中的样本有类似的表示。\n",
    "\n",
    "**多任务学习（Multi-Task Learning）**：通过合并几个任务中的样例（可以视为对参数施加的软约束）来提高泛化的一种方式。 当模型的一部分在任务之间共享时，模型的这一部分更多地被约束为良好的值（假设共享是合理的），往往能更好地泛化。从深度学习的观点看，底层的先验知识如下：能解释数据变化的因素中，某些因素是跨两个或更多任务共享的。\n",
    "![]()\n",
    "\n",
    "**提前停止（Early Stopping）**：我们经常观察到，训练误差会随着时间的推移逐渐降低，但验证集的误差会再次上升。这意味着，如果在验证集误差开始上升的时候提前停止训练，这就是“提前终止”策略。可以获得更好的模型 可能是深度学习中最常用的正则化形式。 它的流行主要是因为有效性和简单性，还可以减少训练过程的计算成本。\n",
    "\n",
    "**参数绑定（Parameter Tying）**：A模型和已经有参数的模型B任务相似，可以让A尽可能接近B，设置罚项：$Ω(w^{(A)},w^{(B)})=‖w^{(A)}−w^{(B)}‖^2_2 $\n",
    "\n",
    "**参数共享（Parameter Sharing）**：直接让A模型的参数等于B模型的参数，典型的应用是CNN。\n",
    "\n",
    "**稀疏表示（Sparse Representation）**：惩罚神经网络中的激活单元，稀疏化激活单元，惩罚项：Ω(h)。稀疏表示和$L^1$正则带来的稀疏参数容易混淆，区别：![]()\n",
    "![]()\n",
    "\n",
    "**Bagging（Bootstrap Aggregating）**：通过结合多个模型来降低泛化误差。这种方法通常又被称为“集成方法”（Ensemble Method）。具体来说，Bagging涉及构造k个不同的数据集，再训练k个模型，集合所有模型的预测结果投票得出最后结果。模型平均是一个减少泛化误差的非常强大可靠的方法。 但在作为科学论文算法的基准时，它通常是不鼓励使用的，因为任何机器学习算法都可以从模型平均中大幅获益\n",
    "\n",
    "**Dropout**：Dropout可以被认为是集成大量深层神经网络的实用Bagging方法。 但是Dropout训练与Bagging训练不太一样。 在Bagging的情况下，所有模型都是独立的。 在Dropout的情况下，所有模型共享参数。 Dropout不仅仅是训练一个Bagging的集成模型， 并且是共享隐藏单元的集成模型。 这意味着无论其他隐藏单元是否在模型中，每个隐藏单元必须都能够表现良好。 隐藏单元必须准备好进行模型之间的交换和互换。 因此Dropout正则化每个隐藏单元不仅是一个很好的特征，更要在许多情况下是良好的特征。 除此之外，计算方便是Dropout的一个优点，Dropout的另一个显著优点是不怎么限制适用的模型或训练过程。 然而，当只有极少的训练样本可用时，Dropout不会很有效。\n",
    "\n",
    "**对抗训练（Adversarial Training）**： 对抗训练通过鼓励网络在训练数据附近的局部区域恒定来限制这一高度敏感的局部线性行为。 这可以被看作是一种明确地向监督神经网络引入局部恒定先验的方法。\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Optimization for Training Deep Models\n",
    "\n",
    "**机器学习和纯优化问题的区别**：机器学习关注某些性能度量P，定义于测试集上并且可能是不可解的，只能间接地优化P。因此通过降低代价函数J(θ)来提高P。 这一点与纯优化不同，纯优化最小化目标J本身。\n",
    "\n",
    "**批量（batch）梯度算法**：使用整个训练集的优化算法被称为批量（batch）或确定性（deterministic）梯度算法。\n",
    "\n",
    "**在线（online）算法**：每次只使用单个样本的优化算法有时被称为随机（stochastic）或者在线（online）算法。\n",
    "\n",
    "**mini batch**：介于以上两者之间，使用一个以上，而又不是全部的训练样本。影响mini batch size的因素：1.更大的批量会计算更精确的梯度估计，但是回报却是小于线性的。2.极小批量通常难以充分利用多核架构。 这促使我们使用一些绝对最小批量，低于这个值的小批量处理不会减少计算时间。3.在某些硬件上使用特定大小的数组时，运行时间会更少。 尤其是在使用GPU时，通常使用2的幂数作为批量大小可以获得更少的运行时间。\n",
    "\n",
    "**局部极小值（local minima）的问题**：如果一个足够大的训练集可以唯一确定一组模型参数，那么该模型被称为可辨认的（identifiable）；而神经网络模型是不可辨认的（最直观的原因就是权重空间对称性，weight space symmetry），这意味着神经网络代价函数具有非常多的局部极小值。 对于足够大的神经网络而言， 大部分局部极小值都具有很小的代价函数，我们能不能找到真正的全局最小点并不重要，而是需要在参数空间中找到一个代价很小（但不是最小）的点。\n",
    "\n",
    "**鞍点（Saddle）的问题**：对于很多高维非凸函数而言，局部极小值事实上远少于另一类梯度为零的点：鞍点。在鞍点处，Hessian矩阵同时具有正负特征值。鞍点激增对训练算法的影响：对于只使用梯度信息的一阶优化算法而言，目前情况还不清楚。 鞍点附近的梯度通常会非常小。 另一方面，实验中梯度下降似乎可以在许多情况下逃离鞍点。对于牛顿法而言，鞍点显然是一个问题。 梯度下降旨在朝”下坡”移动，而非明确寻求临界点。 而牛顿法的目标是寻求梯度为零的点。 高维空间中鞍点的激增或许解释了在神经网络训练中为什么二阶方法无法成功取代梯度下降。 \n",
    "\n",
    "**悬崖（cliffs）和梯度爆炸（exploding gradients）**：多层神经网络通常存在像悬崖一样的斜率较大区域，这是由于几个较大的权重相乘导致的，在RNN中比较常见。 遇到斜率极大的悬崖结构时，梯度更新会很大程度地改变参数值，通常会完全跳过这类悬崖结构。 启发式梯度截断会干涉来减小步长，从而使其不太可能走出梯度近似为最陡下降方向的悬崖区域。\n",
    "![]()\n",
    "\n",
    "**各种优化算法**：\n",
    "\n",
    "**随机梯度下降（Stochastic Gradient Descent）算法**：计算mini-batch中m个样本对应的梯度，取其平均值来更新参数。关键的超参是学习率ϵ。\n",
    "![]()\n",
    "\n",
    "**动量（Momentum）算法**：动量方法旨在加速学习，特别是处理高曲率、小但一致的梯度，或是带噪声的梯度。 动量算法使用变量v（velocity，速度）**积累之前梯度指数级衰减的移动平均**，并且继续沿该方向移动。动量=mv，当m=1时动量即v。如果动量算法总是观测到梯度g，那么它会在方向−g上不停加速，直到达到最终速度，其中步长大小为$\\frac{ϵ‖g‖}{1−α}$。因此将动量的超参数视为$\\frac{1}{1−α}$有助于理解。 例如，α=0.9对应着最大速度10倍于梯度下降算法。\n",
    "![]()\n",
    "\n",
    "**Nesterov 动量算法**：Nesterov 动量算法和普通的动量算法的区别在于梯度计算的位置。\n",
    "![]()\n",
    "\n",
    "**参数初始化策略**：现代的初始化策略是简单的、启发式的。也许完全确知的唯一特性是初始参数需要在不同单元间”破坏对称性”。更大的初始权重具有更强的破坏对称性的作用，有助于避免冗余的单元。有些启发式方法可用于选择权重的初始大小。 一种初始化m个输入和n输出的全连接层的权重的启发式方法是从分布$U(−\\frac{1}{\\sqrt{m}},\\frac{1}{\\sqrt{m}})$中采样权重，另一种使用标准初始化,$?W_{i,j}\\sim U(−\\frac{6}{\\sqrt{m+n}},\\frac{6}{\\sqrt{m+n}})$\n",
    "\n",
    "**自适应学习率的优化算法**：\n",
    "\n",
    "**AdaGrad**：反比于其所有梯度历史平方值总和的平方根来缩放每个参数。 具有损失最大偏导的学习率快速下降，而具有小偏导的学习率下降较慢。AdaGrad在某些深度学习模型上效果不错，但不是全部。\n",
    "![]()\n",
    "\n",
    "**RMSProp**：修改AdaGrad以在非凸设定下效果更好，改变梯度积累为指数加权的移动平均。RMSProp使用指数衰减平均以丢弃遥远过去的历史，使其能够在找到凸碗状结构后快速收敛， 它就像一个初始化于该碗状结构的AdaGrad算法实例。\n",
    "![]()\n",
    "\n",
    "**Adam**：\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Convolutional Networks\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10. Sequence Modeling: Recurrent and Recursive Nets\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Practical Methodology\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Application\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Linear Factor Models\n",
    "\n",
    "**线性因子模型（Linear Factor Models）**：线性因子模型通过随机线性解码器函数来定义，该函数通过对h的线性变换以及添加噪声来生成x。通常包含如下步骤：1.首先，我们从一个分布中采样解释性因子h，$h\\sim p(h)$，其中p(h)是一个因子分布，满足$p(h)=\\prod_i p(h_i)$；2.然后，我们对实值的可观察变量进行采样$x=Wh+b+noise$。\n",
    "\n",
    "**概率PCA、因子分析和其他线性因子模型**仅在对观测到x之前的噪声分布和隐变量h先验的选择上有所不同。\n",
    "\n",
    "**因子分析（Factor Analysis）**：隐变量先验是一个方差为单位矩阵的高斯分布$h \\sim N(h;0,I)$，同时假定在给定h的条件下观察值$x_i$是条件独立的。假设噪声是从对角协方差矩阵的高斯分布中采样的的，协方差矩阵为$ψ=diag(σ^2)$，容易看出，x服从多维正态分布，并满$x\\sim N(x;b,WW^⊤+ψ)$。\n",
    "\n",
    "**概率PCA（Probabilistic PCA）和**：在因子分析的基础上，使条件方差$σ^2_i$等于同一个值。x的协方差简化为$WW^⊤+σ^2_I$，或者等价的$x=Wh+b+σz$，其中$z\\sim N(z;0,I)$\n",
    "\n",
    "**独立成分分析（Independent Component Analysis, ICA）**：主要想法是：通过选择一个独立的p(h)，尽可能地恢复接近独立的潜在因子。每个训练样本对应一个时刻，每个$x_i$是一个传感器对混合信号的观察值，并且每个$h_i$是单个原始信号的一个估计。ICA的所有变种均要求p(h)是非高斯的。 这是因为如果p(h)是具有高斯分量的独立先验，则W是不可识别的。\n",
    "\n",
    "**慢特征分析（Slow Feature Analysis）**：是使用来自时间信号的信息学习不变特征的线性因子模型。慢特征分析的想法源于所谓的慢性原则。 其基本思想是，与场景中起描述作用的单个量度相比，场景的重要特性通常变化得非常缓慢。为了引入慢性原则，我们可以向代价函数添加以下项:$λ\\sum _tL(f(x^{(t+1)}),f(x^{(t)}))$。深度SFA已经被用于学习用在对象识别和姿态估计的特征。但是到目前为止，慢性原则尚未成为任何最先进应用的基础。究竟是什么因素限制了其性能仍有待研究，或许是慢度先验太过强势。\n",
    "\n",
    "**稀疏编码（Sparse Coding）**：是一个线性因子模型，已作为一种无监督特征学习和特征提取机制得到了广泛研究。 严格来说，术语”稀疏编码”是指在该模型中推断h值的过程，而”稀疏建模”是指设计和学习模型的过程，但是通常这两个概念都可以用术语”稀疏编码”描述。 稀疏编码模型通常假设线性因子有一个各向同性精度为β的高斯噪声：$p(x∣h)=N(x;Wh+b,\\frac{1}{β}I)$。分布p(h)通常选取为一个峰值仅在0点很尖锐的分布：$p(h_i)=Laplace(h_i;0,\\frac{2}{λ})=\\frac{λ}{4}e^{−\\frac{1}{2}λ|h_i|}$。$h^*$的表达式里包含了$||h||_1$，这导致了$h^*$向量的稀疏性。\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Autoencoders\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Representation Learning\n",
    "\n",
    "**前馈网络**：我们可以将监督学习训练的前馈网络视为表示学习的一种形式。 具体地，网络的最后一层通常是线性分类器，如softmax回归分类器。 网络的其余部分学习出该分类器的表示。\n",
    "\n",
    "**贪心逐层无监督预训练（Greddy Layer-Wise Unsupervised Pretrain）**：贪心逐层无监督预训练依赖于单层表示学习算法，例如RBM、单层自编码器、稀疏编码模型或其他学习潜在表示的模型。 每一层使用无监督学习预训练，将前一层的输出作为输入，输出数据的新的表示。 贪心逐层无监督预训练被称为贪心的，是因为它是一个贪心算法， 这意味着它独立地优化解决方案的每一个部分，每一步解决一个部分，而不是联合优化所有部分。 它被称为逐层的，是因为这些独立的解决方案是网络层。 具体地，贪心逐层无监督预训练每次处理一层网络，训练第kk层时保持前面的网络层不变。无监督预训练结合了两种不同的想法： 第一，它利用了深度神经网络对初始参数的选择，可以对模型有着显著的正则化效果（在较小程度上，可以改进优化）的想法。 第二，它利用了更一般的想法——学习输入分布有助于学习从输入到输出的映射。\n",
    "![](https://raw.githubusercontent.com/applenob/reading_note/master/res/greedy_pre.png)\n",
    "从无监督预训练作为学习一个表示的角度来看，我们可以期望无监督预训练在初始表示较差的情况下更有效，一个重要的例子是词嵌入。 从无监督预训练作为正则化项的角度来看，我们可以期望无监督预训练在标注样本数量非常小时很有帮助。 大部分算法已经不使用无监督预训练了，但是在自然语言处理领域中单词作为one-hot向量的表示不能传达相似性信息，并且有非常多的未标注数据集可用。 \n",
    "\n",
    "**迁移学习（transfer learning）和领域自适应（domain adaption）**：指的是利用一个情景（例如，分布P1）中已经学到的内容去改善另一个情景（比如分布P2）中的泛化情况。 在迁移学习中，学习器必须执行两个或更多个不同的任务，但是我们假设能够解释P1变化的许多因素和学习P2需要抓住的变化相关。比如，许多视觉类别**共享**一些低级概念，比如边缘、视觉形状、几何变化、光照变化的影响等等。 在领域自适应的相关情况下，在每个情景之间任务（和最优的输入到输出的映射）都是相同的，但是输入分布稍有不同。\n",
    "\n",
    "**一次学习（one shot learning）**： 只有一个标注样本的迁移任务被称为一次学习，第一阶段学习出的表示就可以清楚地分离出潜在的类别，所以一次学习是可能的。 在迁移学习阶段，仅需要一个标注样本来推断表示空间中聚集在相同点周围许多可能测试样本的标签。\n",
    "\n",
    "**零次学习（zero shot learning）**：没有标注样本的迁移任务被称为零次学习，例子：一个学习器已经读取了大量文本，然后要解决对象识别的问题。 如果文本足够好地描述了对象，那么即使没有看到某对象的图像，也能识别出该对象的类别。 例如，已知猫有四条腿和尖尖的耳朵，那么学习器可以在没有见过猫的情况下猜测该图像中是猫。\n",
    "\n",
    "**”什么原因能够使一个表示比另一个表示更好？”**：这是表示学习的一个重要问题。一种假设是，理想表示中的特征对应到观测数据的潜在成因，特征空间中不同的特征或方向对应着不同的原因，从而表示能够区分这些原因。 \n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Structured Probabilistic Models for Deep Learning\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Monte Carlo Methods\n",
    "\n",
    "**随机算法**：随机算法可以粗略地分为两类：拉斯维加斯算法（Las Vegas algorithms）和蒙特卡洛算法（Monte Carlo algorithms）。 \n",
    "\n",
    "**拉斯维加斯算法（Las Vegas algorithms）**：总是精确地返回一个正确答案（或者返回算法失败）。 该方法通常需要占用随机量的计算资源（一般指内存或运行时间）。 \n",
    "\n",
    "**蒙特卡洛算法（Monte Carlo algorithms）**：蒙特卡罗方法返回的答案具有随机大小的错误。 花费更多的计算资源（通常包括内存和运行时间）可以减少这种错误。 在任意固定的计算资源下， 蒙特卡罗算法可以得到一个近似解。\n",
    "\n",
    "**为什么要sampling？**：1.有时我们使用它加速一些很费时却易于处理的求和估计；2.有时我们用sampling去近似一个难以处理的求和或积分；3.还有一些时候，sampling就是我们的目标，例如我们想训练一个可以从训练分布采样的模型。\n",
    "\n",
    "**蒙特卡洛采样的基础（Basics of Monte Carlo Sampling）**：当求和和积分不能直接计算时，我们使用下面的idea：将求和和积分视作某个分布的期望：$s=∑_xp(x)f(x)=E_p[f(x)]$或者$s=∫p(x)f(x)dx=E_p[f(x)]$，然后用平均值去估计它：$\\hat{s_n} = \\frac{1}{n}\\sum_{i=1}^{n}f(x^{(i)})$\n",
    "\n",
    "**重要性采样（Importance Sampling）**：p(x)f(x)重写成：$p(x)f(x) = q(x)\\frac{p(x)f(x)}{q(x)}$，于是，蒙特卡洛Sampling可以转换成重要性Sampling，即从$\\hat{s_p} = \\frac{1}{n}\\sum_{i=1,x^{(i)}\\sim p}^{n}f(x^{(i)})$转换成$\\hat{s_q} = \\frac{1}{n}\\sum_{i=1,x^{(i)}\\sim q}^{n}\\frac {p(x^{(i)})f(x^{(i)})}{q(x^{(i)})}=\\frac{1}{n}\\sum_{i=1,x^{(i)}\\sim q}^{n}w(x^{(i)})f(x^{(i)})$。其中可以把$w(x)=\\frac{p(x)}{q(x)}$称为**重要性权重（importance weight）**\n",
    "\n",
    "**马尔科夫链蒙特卡洛方法**：在深度学习的内容中，有时候需要从目标分布$p_{model}(x)$中精确采样或者一个好的（方差较小的）重要采样分布q(x)，但是又有很多时候不能直接采样，比如使用无向图模型的时候。使用MCMC方法有一个前提：所有的可能状态的概率不能为0，即不可化简性（Irreducibility）。无向图使用的基于能量的模型（Energy Based Model， EBM）保证了这一点。 马尔科夫链（Markov Chain）的核心思想：从某个可取任意值的状态x出发。 随着时间的推移，我们随机地反复更新状态x。最终x成为了一个从近似p(x)中抽出的样本。在正式的定义中，马尔科夫链由一个随机状态x和一个转移分布$T(x′∣x)$定义而成，$T(x′∣x)$是一个概率分布，说明了给定状态x的情况下随机地转移到x′的概率。 运行一个马尔科夫链意味着根据转移分布$T(x′∣x)$采出的值x′来更新状态x。运行马尔科夫链直到它达到均衡分布的过程通常被称为马尔科夫链的磨合过程（burning in）。 mcmc方法抽样的两个连续的样本之间会高度相关，如果我们想要得到完全独立的样本，那么我们可以同时并行地运行多个马尔科夫链。深度学习的从业者们通常选取的马尔科夫链的数目和小批量中的样本数相近，然后从这些固定的马尔科夫链集合中抽取所需要的样本。 马尔科夫链的数目通常选为100。 还有另一个难点是我们无法预先知道马尔可夫链需要运行多少步才能到达均衡分布。 这段时间通常被称为混合时间（mixing time）。\n",
    "\n",
    "**吉布斯采样（Gibbs Sampling）**：其中在基于能量的模型中从T(x′∣x)采样是通过选择一个变量$x_i$，然后从$p_{model}$中该点关于在无向图G（定义了基于能量的模型结构）中邻接点的条件分布中采样。 只要一些变量在给定相邻变量时是条件独立的，那么这些变量就可以被同时采样。 \n",
    "\n",
    "这章可以参考之前的[另一篇关于MCMC的笔记](https://applenob.github.io/1_MCMC.html)，或者直接参考[An Introduction to MCMC for Machine Learning](http://www.cs.princeton.edu/courses/archive/spr06/cos598C/papers/AndrieuFreitasDoucetJordan2003.pdf)，这里是[中文简易翻译版](https://zhuanlan.zhihu.com/p/25610149)。\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Confronting the Partition Function\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Approximate\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Deep Generative Models\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n",
    "****\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
